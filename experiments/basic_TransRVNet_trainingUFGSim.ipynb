{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967697e7-371b-4ecc-8a32-20299f7498cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255556ac-018a-4b5d-804c-0b08dc792f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/colorcloud/colorcloud/lovasz_softmax_loss.py:185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if (classes is 'present' and fg.sum() == 0):\n"
     ]
    }
   ],
   "source": [
    "# from colorcloud.behley2019iccv import plot_projections\n",
    "from colorcloud.cheng2023TransRVNet import TransVRNet\n",
    "from colorcloud.cheng2023TransRVNet import TransRVNet_loss\n",
    "from colorcloud.cheng2023TransRVNet import RandomRotationTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomDroppingPointsTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomSingInvertingTransform\n",
    "from colorcloud.behley2019iccv import SemanticKITTIDataset\n",
    "from colorcloud.behley2019iccv import ProjectionTransform\n",
    "from colorcloud.behley2019iccv import ProjectionToTensorTransform\n",
    "from colorcloud.behley2019iccv import SphericalProjection\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "from torchmetrics.classification import Dice\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fec74-752a-45cc-8094-a5dddc3accf6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6eed986-4cf7-4ee2-a181-1a4f00679964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57660195-b8be-45ea-82d4-ac361abb8612",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convolutions' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6686904-8719-4759-b840-e6204f25860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrciam_p = {\n",
    "    \"p1\": {\n",
    "        \"b1_in\": 1,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"p2\": {\n",
    "        \"b1_in\": 3,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"output_conv\": 192\n",
    "}\n",
    "\n",
    "encoder_p = {\n",
    "    \"module_1\": {\n",
    "        \"in_channels\": 192,\n",
    "        \"conv2_in_channels\": 128,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    },\n",
    "    \"module_2\": {\n",
    "        \"in_channels\": 256,\n",
    "        \"conv2_in_channels\": 256,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    }\n",
    "}\n",
    "\n",
    "decoder_p = {\n",
    "    \"in_channels\": 264,\n",
    "    \"conv2_in_channels\": 128,\n",
    "    \"dilated_conv_in_channels\": 128,\n",
    "    \"dilated_conv_out_channels\": 64,\n",
    "    \"output\": 32\n",
    "}\n",
    "\n",
    "p_bntm = {\n",
    "    \"window_size\": (4,4),\n",
    "    \"embed_dim\": int(encoder_p[\"module_2\"][\"residual_out_channels\"]/8)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cff5f-ad7b-4922-92aa-c81fede806e9",
   "metadata": {},
   "source": [
    "## Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c202e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset:  15237\n",
      "Size of val dataset:  709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/colorcloud/colorcloud/behley2019iccv.py:59: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.content_weights = 1./content_sum_np\n"
     ]
    }
   ],
   "source": [
    "proj = SphericalProjection(fov_up_deg=15., fov_down_deg=-15., W=1024, H=16)\n",
    "scaling_values = {\n",
    "    \"x\" : {\"min\": -150., \"max\":150.},\n",
    "    \"y\" : {\"min\": -150., \"max\":150.},\n",
    "    \"z\" : {\"min\": -10., \"max\":30.},\n",
    "    \"r\" : {\"min\": 0., \"max\":1.},\n",
    "    \"d\" : {\"min\": 0., \"max\":130.}\n",
    "}\n",
    "data_path = '/workspace/data'\n",
    "train_dataset = SemanticKITTIDataset(data_path=data_path, split='train', ufg_dataset=True)\n",
    "val_dataset = SemanticKITTIDataset(data_path='/workspace/data2', split='valid', ufg_dataset=True)\n",
    "\n",
    "aug_tfms = v2.Compose([\n",
    "    RandomDroppingPointsTransform(),\n",
    "    RandomRotationTransform(),\n",
    "    RandomSingInvertingTransform(),\n",
    "    ProjectionTransform(proj),\n",
    "    ProjectionToTensorTransform(),\n",
    "])\n",
    "\n",
    "train_dataset.set_transform(aug_tfms)\n",
    "val_dataset.set_transform(aug_tfms)\n",
    "\n",
    "print(\"Size of train dataset: \", len(train_dataset))\n",
    "print(\"Size of val dataset: \", len(val_dataset))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7e8b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['frame', 'label', 'mask'])\n",
      "torch.Size([5, 16, 1024]) torch.float32\n",
      "torch.Size([16, 1024]) torch.int32\n",
      "torch.Size([16, 1024]) torch.bool\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0].keys())\n",
    "print(train_dataset[0]['frame'].shape, train_dataset[0]['frame'].dtype)\n",
    "print(train_dataset[0]['label'].shape, train_dataset[0]['label'].dtype)\n",
    "print(train_dataset[0]['mask'].shape, train_dataset[0]['mask'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a193e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps\n",
    "n_epochs = 1\n",
    "train_steps = len(train_loader) // batch_size\n",
    "test_steps = len(val_loader) // batch_size\n",
    "total_steps = train_steps * n_epochs\n",
    "H = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "model = TransVRNet(mrciam_p, encoder_p, decoder_p, p_bntm, N_CLASSES=9, using_reflectance=True, ufg_format=True).to(device)\n",
    "# loss function\n",
    "loss_func = TransRVNet_loss(device=device, file_name_yaml='semantic-kitti.yaml')\n",
    "# optimizer\n",
    "opt = AdamW(model.parameters(), lr=5e-4, eps=1e-5, weight_decay=0.0001)\n",
    "lr_scheduler = OneCycleLR(opt, max_lr=0.002, div_factor=1, final_div_factor=10, steps_per_epoch=total_steps, epochs=30)\n",
    "# dropout\n",
    "dropout = torch.nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "\n",
    "# metrics\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=model.n_classes).to(device)\n",
    "accuracy_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "miou = MeanIoU(num_classes=model.n_classes).to(device)\n",
    "miou_dict = {\"train\": [], \"val\": []}\n",
    "miou_per_class = MeanIoU(num_classes=model.n_classes, per_class=True).to(device)\n",
    "miou_per_class_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "dice = Dice(num_classes=model.n_classes).to(device)\n",
    "dice_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "mcf1s = MulticlassF1Score(num_classes=model.n_classes, average=\"macro\").to(device)\n",
    "mcf1s_dict = {\"train\": [], \"val\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2d8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epochs in tqdm(range(n_epochs)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "        img, label, mask = train_item['frame'], train_item['label'], train_item['mask']\n",
    "        label = label.to(torch.int64)\n",
    "        # print('raw label: ', label.shape, label.dtype)\n",
    "\n",
    "        # Separate channels\n",
    "        xyz = img[:, :3, :, :]\n",
    "        # passando so um tensor do shape esperado pela reflectancia, mesmo nao sendo utilizada no modelo\n",
    "        reflectance = img[:, 3, :, :].unsqueeze(1)\n",
    "        depth = img[:, 4, :, :].unsqueeze(1)        \n",
    "\n",
    "        pred = model(xyz, depth, reflectance)\n",
    "\n",
    "        # Apply dropout\n",
    "        pred = dropout(pred)\n",
    "\n",
    "        label[~mask] = 0\n",
    "        # print('label: ', label.shape, label.dtype)\n",
    "        train_loss = loss_func(pred, label, mask)\n",
    "\n",
    "        pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "        pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "        mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "        pred_m = pred_f[mask_f, :]\n",
    "        label_m = label[mask]\n",
    "\n",
    "        current_train_acc = accuracy(pred_m, label_m)\n",
    "        accuracy_dict[\"train\"].append(current_train_acc)\n",
    "        pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "        mask_miou = (label != 0)\n",
    "        pred_labels[~mask] = 0\n",
    "        # print('pred: ', pred.shape, pred.dtype, pred)\n",
    "        # print('pred labels: ', pred_labels.shape, pred_labels.dtype, pred_labels)\n",
    "        # print('label: ', label.shape, label)\n",
    "        current_train_miou = miou(pred_labels, label)\n",
    "        miou_dict[\"train\"].append(current_train_miou)\n",
    "        current_train_miou_per_class = miou_per_class(pred_labels, label)\n",
    "        miou_per_class_dict[\"train\"].append(current_train_miou_per_class)\n",
    "        current_train_dice = dice(pred_labels, label)\n",
    "        dice_dict[\"train\"].append(current_train_dice)\n",
    "        current_train_mcf1s = mcf1s(pred_labels, label)\n",
    "        mcf1s_dict[\"train\"].append(current_train_mcf1s)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in val_loader:\n",
    "            test_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img, label, mask = train_item['frame'], train_item['label'], train_item['mask']\n",
    "            label = label.to(torch.int64)\n",
    " \n",
    "            # Separate channels\n",
    "            xyz = img[:, :3, :, :]\n",
    "            depth = img[:, 3, :, :].unsqueeze(1)\n",
    "            reflectance = img[:, 4, :].unsqueeze(1)\n",
    "\n",
    "            pred = model(xyz, depth, reflectance)\n",
    "\n",
    "            label[~mask] = 0\n",
    "\n",
    "            test_loss = loss_func(pred, label, mask)\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "\n",
    "            current_test_acc = accuracy(pred_m, label_m)\n",
    "            accuracy_dict[\"val\"].append(current_test_acc)\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "            current_test_miou = miou(pred_labels, label)\n",
    "            miou_dict[\"val\"].append(current_test_miou)\n",
    "            current_train_miou_per_class = miou_per_class(pred_labels, label)\n",
    "            miou_per_class_dict[\"val\"].append(current_train_miou_per_class)\n",
    "            current_test_dice = dice(pred_labels, label)\n",
    "            dice_dict[\"val\"].append(current_test_dice)\n",
    "            current_test_mcf1s = mcf1s(pred_labels, label)\n",
    "            mcf1s_dict[\"val\"].append(current_test_mcf1s)\n",
    "        \n",
    "            total_test_loss += test_loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_test_loss = total_test_loss / test_steps\n",
    "\n",
    "    # Store loss history for graphical visualization\n",
    "    H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
    "\n",
    "    print(\"CURRENT EPOCH: {}/{}\".format(epochs + 1, n_epochs))\n",
    "    print(\"Train loss: {:.10f}, Test loss {:.4f}\".format(avg_train_loss, avg_test_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training took {:.2f}s\".format(end_time - start_time))\n",
    "print(\"Accuracy: {:.4f} on training and {:.4f} on testing\".format(current_train_acc, current_test_acc))\n",
    "print(\"Mean IOU: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"Dice: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"F1 Macro: {:.4f} on training and {:.4f} on testing\".format(current_train_mcf1s, current_test_mcf1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = \"ufgsim_transRVNet_torch.pt\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f596aa",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "train_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"train\"]]\n",
    "val_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "train_miou = [x.cpu().numpy() for x in miou_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_miou, label=\"train_miou\")\n",
    "plt.plot(val_miou, label=\"val_miou\")\n",
    "plt.title(\"Mean IOU\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"miou\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU per class\n",
    "train_miou = [x.cpu().numpy() for x in miou_per_class_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_per_class_dict[\"val\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "mean_train_miou = np.mean(train_miou, axis=0)\n",
    "mean_val_miou = np.mean(val_miou, axis=0)\n",
    "\n",
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "mean_train_miou = mean_train_miou[:13]\n",
    "mean_val_miou = mean_val_miou[:13]\n",
    "\n",
    "# Número de classes\n",
    "num_classes = mean_train_miou.shape[0]\n",
    "classes = [f'Classe {i+1}' for i in range(num_classes)]\n",
    "\n",
    "# Plotando o gráfico de barras para Mean IoU de treino e validação\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(num_classes)\n",
    "\n",
    "# Barras para treino e validação\n",
    "plt.bar(index, mean_train_miou, bar_width, label='Treino', color='salmon', edgecolor='black')\n",
    "plt.bar(index + bar_width, mean_val_miou, bar_width, label='Validação', color='skyblue', edgecolor='black')\n",
    "\n",
    "# Configuração dos eixos e títulos\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.title('Mean IoU Médio por Classe para Treino e Validação')\n",
    "plt.xticks(index + bar_width / 2, classes, rotation=45)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte as listas de arrays para arrays 2D para cada variável\n",
    "train_miou = np.array(train_miou)\n",
    "val_miou = np.array(val_miou)\n",
    "\n",
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "mean_train_miou = np.mean(train_miou, axis=0)\n",
    "mean_val_miou = np.mean(val_miou, axis=0)\n",
    "\n",
    "# Plotando os histogramas para os vetores médios de Mean IoU de treino e validação\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histograma do conjunto de treino\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(mean_train_miou, bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Histograma do Mean IoU Médio por Classe (Treino)')\n",
    "plt.xlabel('Mean IoU')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Histograma do conjunto de validação\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mean_val_miou, bins=10, color='salmon', edgecolor='black')\n",
    "plt.title('Histograma do Mean IoU Médio por Classe (Validação)')\n",
    "plt.xlabel('Mean IoU')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Ajusta o layout e exibe o gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice\n",
    "train_dice = [x.cpu().numpy() for x in dice_dict[\"train\"]]\n",
    "val_dice = [x.cpu().numpy() for x in dice_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_dice, label=\"train_dice\")\n",
    "plt.plot(val_dice, label=\"val_dice\")\n",
    "plt.title(\"Dice\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"dice score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b54ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Macro\n",
    "train_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"train\"]]\n",
    "val_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_mcf1s, label=\"train_mcf1s\")\n",
    "plt.plot(val_mcf1s, label=\"val_mcf1s\")\n",
    "plt.title(\"F1 Macro\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"mcf1s score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704b582",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('ufgsim_transRVNet_torch.pt', weights_only=False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375dbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "item = None\n",
    "learning_map_inv_np = val_dataset.learning_map_inv_np\n",
    "color_map_rgb_np = val_dataset.color_map_rgb_np\n",
    "\n",
    "color_pred = None\n",
    "\n",
    "channels=['x', 'y', 'z']\n",
    "channels_map = {\"x\": 0, \"y\": 1, \"z\": 2, \"d\": 3}\n",
    "num_channels = len(channels)\n",
    "fig_size_vertical = 2*num_channels\n",
    "\n",
    "for batch in val_loader:\n",
    "    train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "    img, label, m = train_item['frame'], train_item['label'], train_item['mask']\n",
    "\n",
    "    mask = m.cpu().squeeze(0).detach().numpy()\n",
    "    item = train_item\n",
    "\n",
    "    cpuimg = img.cpu()\n",
    "    # Separate channels\n",
    "    xyz = img[:, :3, :, :]\n",
    "    # passando so um tensor do shape esperado pela reflectancia, mesmo nao sendo utilizada no modelo\n",
    "    reflectance = img[:, 3, :, :].unsqueeze(1)\n",
    "    depth = img[:, 4, :, :].unsqueeze(1)      \n",
    "\n",
    "    p = torch.argmax(model(xyz, depth, reflectance).cpu(), dim=1).squeeze(0).detach().numpy()\n",
    "\n",
    "    print(mask.shape, mask.dtype)\n",
    "    print(p.shape, p.dtype)\n",
    "    print(learning_map_inv_np.shape)\n",
    "\n",
    "    valid_indices = np.clip(p[mask], 0, len(learning_map_inv_np) - 1)\n",
    "    p[mask] = learning_map_inv_np[valid_indices]\n",
    "    colored_label_img = np.zeros(p.shape + (3,))\n",
    "    colored_label_img[mask] = color_map_rgb_np[p[mask]]\n",
    "    colored_label_img = colored_label_img.astype(int)\n",
    "\n",
    "    color_pred = colored_label_img\n",
    "\n",
    "    print(color_pred.shape)\n",
    "    item['label'] = p\n",
    "    # pred.append(torch.argmax(model(depth, depth, xyz).cpu().squeeze(0), dim=0))\n",
    "    # plot_projections(cpuimg[0].data, color_pred, channels=['x'], channels_map=channels_map)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_projections(cpuimg[0].data, color_pred, channels=['x'], channels_map=channels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d500e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc12e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
