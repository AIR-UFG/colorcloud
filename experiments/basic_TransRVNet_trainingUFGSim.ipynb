{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967697e7-371b-4ecc-8a32-20299f7498cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255556ac-018a-4b5d-804c-0b08dc792f2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from colorcloud.behley2019iccv import plot_projections\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcolorcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheng2023TransRVNet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransVRNet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcolorcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheng2023TransRVNet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransRVNet_loss\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcolorcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheng2023TransRVNet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomRotationTransform\n",
      "File \u001b[0;32m/workspace/colorcloud/colorcloud/cheng2023TransRVNet.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcheckpoint\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningModule\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/__init__.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# This needs to be early as other modules call it.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mterm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m termsetup, termlog, termerror, termwarn\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sdk \u001b[38;5;28;01mas\u001b[39;00m wandb_sdk\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m     25\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwandb_lib \u001b[38;5;241m=\u001b[39m wandb_sdk\u001b[38;5;241m.\u001b[39mlib  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/__init__.py:25\u001b[0m\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSettings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wandb_helper \u001b[38;5;28;01mas\u001b[39;00m helper\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifacts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Artifact\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_alerts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlertLevel\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/artifacts/artifact.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_types, env, util\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_exceptions\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpublic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArtifactCollection, ArtifactFiles, RetryingClient, Run\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WBValue\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/apis/__init__.py:43\u001b[0m\n\u001b[1;32m     38\u001b[0m     _disable_ssl()\n\u001b[1;32m     41\u001b[0m reset_path \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mvendor_setup()\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Api \u001b[38;5;28;01mas\u001b[39;00m InternalApi  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpublic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Api \u001b[38;5;28;01mas\u001b[39;00m PublicApi  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     46\u001b[0m reset_path()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/apis/internal.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Api \u001b[38;5;28;01mas\u001b[39;00m InternalApi\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mApi\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal proxy to the official internal API.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py:57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m credentials, retry\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilenames\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DIFF_FNAME, METADATA_FNAME\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgitlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GitRepo\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprogress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Progress\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/gitlib.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         GitCommandError,\n\u001b[1;32m     12\u001b[0m         InvalidGitRepositoryError,\n\u001b[1;32m     13\u001b[0m         NoSuchPathError,\n\u001b[1;32m     14\u001b[0m         Repo,\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     Repo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/git/__init__.py:100\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgitdb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_hex_sha\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    101\u001b[0m     AmbiguousObjectName,\n\u001b[1;32m    102\u001b[0m     BadName,\n\u001b[1;32m    103\u001b[0m     BadObject,\n\u001b[1;32m    104\u001b[0m     BadObjectType,\n\u001b[1;32m    105\u001b[0m     CacheError,\n\u001b[1;32m    106\u001b[0m     CheckoutError,\n\u001b[1;32m    107\u001b[0m     CommandError,\n\u001b[1;32m    108\u001b[0m     GitCommandError,\n\u001b[1;32m    109\u001b[0m     GitCommandNotFound,\n\u001b[1;32m    110\u001b[0m     GitError,\n\u001b[1;32m    111\u001b[0m     HookExecutionError,\n\u001b[1;32m    112\u001b[0m     InvalidDBRoot,\n\u001b[1;32m    113\u001b[0m     InvalidGitRepositoryError,\n\u001b[1;32m    114\u001b[0m     NoSuchPathError,\n\u001b[1;32m    115\u001b[0m     ODBError,\n\u001b[1;32m    116\u001b[0m     ParseError,\n\u001b[1;32m    117\u001b[0m     RepositoryDirtyError,\n\u001b[1;32m    118\u001b[0m     UnmergedEntriesError,\n\u001b[1;32m    119\u001b[0m     UnsafeOptionError,\n\u001b[1;32m    120\u001b[0m     UnsafeProtocolError,\n\u001b[1;32m    121\u001b[0m     UnsupportedOperation,\n\u001b[1;32m    122\u001b[0m     WorkTreeRepositoryUnsupported,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PathLike\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/git/exc.py:47\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgitdb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     AmbiguousObjectName,\n\u001b[1;32m     37\u001b[0m     BadName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     UnsupportedOperation,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m safe_decode\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_password_if_present\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# typing ----------------------------------------------------\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Sequence, Tuple, TYPE_CHECKING, Union\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/git/util.py:89\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# typing ---------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     69\u001b[0m     Any,\n\u001b[1;32m     70\u001b[0m     AnyStr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     overload,\n\u001b[1;32m     87\u001b[0m )\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Git\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GitConfigParser, SectionConstraint\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from colorcloud.behley2019iccv import plot_projections\n",
    "from colorcloud.cheng2023TransRVNet import TransVRNet\n",
    "from colorcloud.cheng2023TransRVNet import TransRVNet_loss\n",
    "from colorcloud.cheng2023TransRVNet import RandomRotationTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomDroppingPointsTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomSingInvertingTransform\n",
    "from colorcloud.behley2019iccv import SemanticKITTIDataset\n",
    "from colorcloud.behley2019iccv import ProjectionTransform\n",
    "from colorcloud.behley2019iccv import ProjectionToTensorTransform\n",
    "from colorcloud.behley2019iccv import SphericalProjection\n",
    "from colorcloud.behley2019iccv import ProjectionVizTransform\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "from torchmetrics.classification import Dice\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fec74-752a-45cc-8094-a5dddc3accf6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eed986-4cf7-4ee2-a181-1a4f00679964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809f11e",
   "metadata": {},
   "source": [
    "## Memory visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._record_memory_history(max_entries=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57660195-b8be-45ea-82d4-ac361abb8612",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convolutions' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6686904-8719-4759-b840-e6204f25860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrciam_p = {\n",
    "    \"p1\": {\n",
    "        \"b1_in\": 1,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"p2\": {\n",
    "        \"b1_in\": 3,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"output_conv\": 192\n",
    "}\n",
    "\n",
    "encoder_p = {\n",
    "    \"module_1\": {\n",
    "        \"in_channels\": 192,\n",
    "        \"conv2_in_channels\": 128,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    },\n",
    "    \"module_2\": {\n",
    "        \"in_channels\": 256,\n",
    "        \"conv2_in_channels\": 256,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    } \n",
    "}\n",
    "\n",
    "decoder_p = {\n",
    "    \"in_channels\": 264,\n",
    "    \"conv2_in_channels\": 128,\n",
    "    \"dilated_conv_in_channels\": 128,\n",
    "    \"dilated_conv_out_channels\": 64,\n",
    "    \"output\": 32\n",
    "}\n",
    "\n",
    "p_bntm = {\n",
    "    \"window_size\": (4,4),\n",
    "    \"embed_dim\": int(encoder_p[\"module_2\"][\"residual_out_channels\"]/8)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d890da",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projections(img, label):\n",
    "    _, axs = plt.subplots(6, 1, figsize=(20,10), layout='compressed')\n",
    "    for i, (ax, title) in enumerate(zip(axs, ['x', 'y', 'z', 'r', 'd', 'label'])): # type: ignore\n",
    "        if i < 5:\n",
    "            ax.imshow(img[:,:,i])\n",
    "        else:\n",
    "            ax.imshow(label)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083794e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset:  5\n"
     ]
    }
   ],
   "source": [
    "data_path = '/workspace/data'\n",
    "train_dataset = SemanticKITTIDataset(data_path=data_path, split='train')\n",
    "print(\"Size of train dataset: \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = SphericalProjection(fov_up_deg=3., fov_down_deg=-25., W=1024, H=64)\n",
    "\n",
    "scaling_values = {\n",
    "    \"x\" : {\"min\": -150., \"max\":150.},\n",
    "    \"y\" : {\"min\": -150., \"max\":150.},\n",
    "    \"z\" : {\"min\": -10., \"max\":30.},\n",
    "    \"r\" : {\"min\": 0., \"max\":1.},\n",
    "    \"d\" : {\"min\": 0., \"max\":130.}\n",
    "}\n",
    "\n",
    "aug_tfms = v2.Compose([\n",
    "    RandomDroppingPointsTransform(),\n",
    "    RandomRotationTransform(),\n",
    "    RandomSingInvertingTransform(),\n",
    "    ProjectionTransform(proj),\n",
    "    ProjectionVizTransform(train_dataset.color_map_rgb_np, train_dataset.learning_map_inv_np, scaling_values),\n",
    "])\n",
    "\n",
    "train_dataset.set_transform(aug_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc661738",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m label \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/workspace/colorcloud/colorcloud/behley2019iccv.py:125\u001b[0m, in \u001b[0;36mSemanticKITTIDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    119\u001b[0m item \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m: frame,\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: label,\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m: mask\n\u001b[1;32m    123\u001b[0m }\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m--> 125\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimple_resize:\n\u001b[1;32m    127\u001b[0m         item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;241m4\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/colorcloud/colorcloud/behley2019iccv.py:306\u001b[0m, in \u001b[0;36mProjectionVizTransform.forward\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    304\u001b[0m normalized_frame_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frame_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale(frame_img[:,:,\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    308\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale(frame_img[:,:,\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/workspace/colorcloud/colorcloud/behley2019iccv.py:293\u001b[0m, in \u001b[0;36mProjectionVizTransform.scale\u001b[0;34m(self, img, min_value, max_value)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscale\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, min_value, max_value):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m img\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_value\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m img\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_value\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m max_value \u001b[38;5;241m>\u001b[39m min_value\n\u001b[1;32m    296\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mclip(min_value, max_value)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "item = train_dataset[0]\n",
    "img = item['frame']\n",
    "label = item['label']\n",
    "\n",
    "plot_projections(img, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b3269",
   "metadata": {},
   "source": [
    "# Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/workspace/data'\n",
    "train_dataset   = SemanticKITTIDataset(data_path=data_path, split='train')\n",
    "val_dataset     = SemanticKITTIDataset(data_path=data_path, split='valid')\n",
    "test_dataset    = SemanticKITTIDataset(data_path=data_path, split='test' )\n",
    "\n",
    "print(\"Size of train dataset:   \", len(train_dataset))\n",
    "print(\"Size of val dataset:     \", len(val_dataset  ))\n",
    "print(\"Size of test dataset:    \", len(test_dataset ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = SphericalProjection(fov_up_deg=3., fov_down_deg=-25., W=1024, H=64)\n",
    "scaling_values = {\n",
    "    \"x\" : {\"min\": -150., \"max\":150.},\n",
    "    \"y\" : {\"min\": -150., \"max\":150.},\n",
    "    \"z\" : {\"min\": -10., \"max\":30.},\n",
    "    \"r\" : {\"min\": 0., \"max\":1.},\n",
    "    \"d\" : {\"min\": 0., \"max\":130.}\n",
    "}\n",
    "aug_tfms = v2.Compose([\n",
    "    RandomDroppingPointsTransform(),\n",
    "    RandomRotationTransform(),\n",
    "    RandomSingInvertingTransform(),\n",
    "    ProjectionTransform(proj),\n",
    "    ProjectionToTensorTransform(),\n",
    "])\n",
    "\n",
    "train_dataset.set_transform(aug_tfms)\n",
    "val_dataset.set_transform(aug_tfms)\n",
    "test_dataset.set_transform(aug_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a848edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps\n",
    "n_epochs = 1\n",
    "train_steps = len(train_loader) // batch_size\n",
    "val_steps = len(val_loader) // batch_size\n",
    "test_steps = len(test_loader) // batch_size\n",
    "total_steps = train_steps * n_epochs\n",
    "\n",
    "H = {\"train_loss\": [], \"val_loss\": []} # store loss history\n",
    "\n",
    "model = TransVRNet(mrciam_p, encoder_p, decoder_p, p_bntm, N_CLASSES=20, using_reflectance=True).to(device)\n",
    "# loss function\n",
    "loss_func = TransRVNet_loss(device=device, file_name_yaml='semantic-kitti.yaml')\n",
    "# optimizer\n",
    "opt = AdamW(model.parameters(), lr=5e-4, eps=1e-5, weight_decay=0.0001)\n",
    "lr_scheduler = OneCycleLR(opt, max_lr=0.002, div_factor=1, final_div_factor=10, steps_per_epoch=total_steps, epochs=30)\n",
    "# dropout\n",
    "dropout = torch.nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "# metrics\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=model.n_classes, average=None).to(device)\n",
    "accuracy_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "# Mean IoU\n",
    "miou = MeanIoU(num_classes=model.n_classes, per_class=True).to(device)  # Ajuste aqui\n",
    "miou_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "dice = Dice(num_classes=model.n_classes).to(device)\n",
    "dice_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "# Multiclass F1 Score\n",
    "mcf1s = MulticlassF1Score(num_classes=model.n_classes, average=None).to(device)\n",
    "mcf1s_dict = {\"train\": [], \"val\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"T\", leave=True):\n",
    "        train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "        img = train_item['frame']\n",
    "        label = train_item['label'].to(torch.int64)\n",
    "        mask = train_item['mask']\n",
    "\n",
    "        label[~mask] = 0\n",
    "\n",
    "        # Separate channels\n",
    "        xyz = img[:, :3, :, :]\n",
    "        reflectance = img[:, 3, :, :].unsqueeze(1)\n",
    "        depth = img[:, 4, :, :].unsqueeze(1)        \n",
    "\n",
    "        pred = model(xyz, depth, reflectance)\n",
    "\n",
    "        # Apply dropout\n",
    "        pred = dropout(pred)\n",
    "\n",
    "        train_loss = loss_func(pred, label, mask)\n",
    "\n",
    "        pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "        pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "        mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "        pred_m = pred_f[mask_f, :]\n",
    "        label_m = label[mask]\n",
    "\n",
    "        current_train_acc = accuracy(pred_m, label_m)\n",
    "        accuracy_dict[\"train\"].append(current_train_acc.cpu().detach().numpy())\n",
    "\n",
    "        pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "        mask_miou = (label != 0)\n",
    "        pred_labels[~mask] = 0\n",
    "        current_train_miou = miou(pred_labels, label)\n",
    "        miou_dict[\"train\"].append(current_train_miou.cpu().detach().numpy())\n",
    "        current_train_dice = dice(pred_labels, label)\n",
    "        dice_dict[\"train\"].append(current_train_dice.cpu().detach().numpy())\n",
    "        current_train_mcf1s = mcf1s(pred_labels, label)\n",
    "        mcf1s_dict[\"train\"].append(current_train_mcf1s.cpu().detach().numpy())\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in tqdm(val_loader, desc=\"E\", leave=True):\n",
    "            val_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img = val_item['frame']\n",
    "            label = val_item['label'].to(torch.int64)\n",
    "            mask = val_item['mask']\n",
    " \n",
    "            label[~mask] = 0\n",
    "\n",
    "            # Separate channels\n",
    "            xyz = img[:, :3, :, :]\n",
    "            depth = img[:, 3, :, :].unsqueeze(1)\n",
    "            reflectance = img[:, 4, :].unsqueeze(1)\n",
    "\n",
    "            pred = model(xyz, depth, reflectance)\n",
    "\n",
    "            val_loss = loss_func(pred, label, mask)\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "            current_val_acc = accuracy(pred_m, label_m)\n",
    "            accuracy_dict[\"val\"].append(current_val_acc.cpu().detach().numpy())\n",
    "\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "            current_val_miou = miou(pred_labels, label)\n",
    "            miou_dict[\"val\"].append(current_val_miou.cpu().detach().numpy())\n",
    "            current_val_dice = dice(pred_labels, label)\n",
    "            dice_dict[\"val\"].append(current_val_dice.cpu().detach().numpy())\n",
    "            current_val_mcf1s = mcf1s(pred_labels, label)\n",
    "            mcf1s_dict[\"val\"].append(current_val_mcf1s.cpu().detach().numpy())\n",
    "        \n",
    "            total_val_loss += val_loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_val_loss = total_val_loss / val_steps\n",
    "\n",
    "    # Store loss history for graphical visualization\n",
    "    H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy()) \n",
    "    H[\"val_loss\"].append(avg_val_loss.cpu().detach().numpy())\n",
    "\n",
    "    print(\"CURRENT EPOCH: {}/{}\".format(epoch + 1, n_epochs))\n",
    "    print(\"Train loss:    {:.10f}, Val loss {:.4f}\".format(avg_train_loss, avg_val_loss))\n",
    "\n",
    "    # model_name = f\"../../data/modelos/{epoch}_transRVNet_torch.pt\"\n",
    "    # torch.save(model, model_name)\n",
    "\n",
    "    torch.cuda.empty_cache()  # Opcional: libera cache da GPU após cada época\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Training took {:.2f}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._dump_snapshot(\"../../data/profile.pkl\")\n",
    "torch.cuda.memory._record_memory_history(enabled=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2560ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"unlabeled\", \"car\", \"bicycle\", \"motorcycle\", \"truck\", \"other-vehicle\",\n",
    "    \"person\", \"bicyclist\", \"motorcyclist\", \"road\", \"parking\", \"sidewalk\",\n",
    "    \"other-ground\", \"building\", \"fence\", \"vegetation\", \"trunk\", \"terrain\",\n",
    "    \"pole\", \"traffic-sign\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55024c6f",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar o tensor em uma lista e criar pares classe-valor\n",
    "current_train_acc_cpu = current_train_acc.cpu().numpy()  # Mover para CPU para manipulação\n",
    "results = zip(classes, current_train_acc_cpu)\n",
    "\n",
    "# Exibir resultados formatados\n",
    "print(\"Accuracy por classe on training:\")\n",
    "for cls, acc in results:\n",
    "    print(f\"{cls:>15}: {acc:.4f}\")\n",
    "\n",
    "# Transformar o tensor em uma lista e criar pares classe-valor\n",
    "current_val_acc_cpu = current_val_acc.cpu().numpy()  # Mover para CPU para manipulação\n",
    "results = zip(classes, current_val_acc_cpu)\n",
    "\n",
    "# Exibir resultados formatados\n",
    "print(\"Accuracy por classe on val:\")\n",
    "for cls, acc in results:\n",
    "    print(f\"{cls:>15}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332abc05",
   "metadata": {},
   "source": [
    "### Mean IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar o tensor em uma lista e criar pares classe-valor\n",
    "current_train_miou_cpu = current_train_miou.cpu().numpy()  # Mover para CPU para manipulação\n",
    "results = zip(classes, current_train_miou_cpu)\n",
    "\n",
    "# Exibir resultados formatados\n",
    "print(\"Mean IOU por classe on training:\")\n",
    "for cls, acc in results:\n",
    "    print(f\"{cls:>15}: {acc:.4f}\")\n",
    "\n",
    "# Transformar o tensor em uma lista e criar pares classe-valor\n",
    "current_val_miou_cpu = current_val_miou.cpu().numpy()  # Mover para CPU para manipulação\n",
    "results = zip(classes, current_val_miou_cpu)\n",
    "\n",
    "# Exibir resultados formatados\n",
    "print(\"Mean IOU por classe on val:\")\n",
    "for cls, acc in results:\n",
    "    print(f\"{cls:>15}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0fb7dd",
   "metadata": {},
   "source": [
    "### Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1568f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Dice: {:.4f} on training and {:.4f} on testing\".format(current_train_dice, current_val_dice))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a50ec",
   "metadata": {},
   "source": [
    "### F1 Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar o tensor em uma lista e criar pares classe-valor\n",
    "current_train_mcf1s_cpu = current_train_mcf1s.cpu().numpy()  # Mover para CPU para manipulação\n",
    "results = zip(classes, current_train_mcf1s_cpu)\n",
    "\n",
    "# Exibir resultados formatados\n",
    "print(\"F1 Macro por classe on training:\")\n",
    "for cls, acc in results:\n",
    "    print(f\"{cls:>15}: {acc:.4f}\")\n",
    "\n",
    "# Transformar o tensor em uma lista e criar pares classe-valor\n",
    "current_val_mcf1s_cpu = current_val_mcf1s.cpu().numpy()  # Mover para CPU para manipulação\n",
    "results = zip(classes, current_val_mcf1s_cpu)\n",
    "\n",
    "# Exibir resultados formatados\n",
    "print(\"F1 Macro por classe on val:\")\n",
    "for cls, acc in results:\n",
    "    print(f\"{cls:>15}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = \"transRVNet_torch.pt\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f596aa",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "train_accuracy = [x.sum()/20 for x in accuracy_dict[\"train\"]]\n",
    "val_accuracy = [x.sum()/20 for x in accuracy_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Steps #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "# train_miou = [x.cpu().numpy() for x in miou_dict[\"train\"]]\n",
    "# val_miou = [x.cpu().numpy() for x in miou_dict[\"val\"]]\n",
    "\n",
    "train_miou = [x.sum()/20 for x in miou_dict[\"train\"]]\n",
    "val_miou = [x.sum()/20 for x in miou_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_miou, label=\"train_miou\")\n",
    "plt.plot(val_miou, label=\"val_miou\")\n",
    "plt.title(\"Mean IOU\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"miou\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_miou = [x for x in miou_dict[\"train\"]]\n",
    "val_miou = [x for x in miou_dict[\"val\"]]\n",
    "\n",
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "mean_train_miou = np.mean(train_miou, axis=0)\n",
    "mean_val_miou = np.mean(val_miou, axis=0)\n",
    "\n",
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "# mean_train_miou = mean_train_miou[:13]\n",
    "# mean_val_miou = mean_val_miou[:13]\n",
    "\n",
    "# Número de classes\n",
    "num_classes = mean_train_miou.shape[0]\n",
    "classes = [f'Classe {i+1}' for i in range(num_classes)]\n",
    "\n",
    "# Plotando o gráfico de barras para Mean IoU de treino e validação\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(num_classes)\n",
    "\n",
    "# Barras para treino e validação\n",
    "plt.bar(index, mean_train_miou, bar_width, label='Treino', color='salmon', edgecolor='black')\n",
    "plt.bar(index + bar_width, mean_val_miou, bar_width, label='Validação', color='skyblue', edgecolor='black')\n",
    "\n",
    "# Configuração dos eixos e títulos\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.title('Mean IoU Médio por Classe para Treino e Validação')\n",
    "plt.xticks(index + bar_width / 2, classes, rotation=45)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice\n",
    "train_dice = [x for x in dice_dict[\"train\"]]\n",
    "val_dice = [x for x in dice_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_dice, label=\"train_dice\")\n",
    "plt.plot(val_dice, label=\"val_dice\")\n",
    "plt.title(\"Dice\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"dice score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b54ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Macro\n",
    "train_mcf1s = [x.sum()/20 for x in mcf1s_dict[\"train\"]]\n",
    "val_mcf1s = [x.sum()/20 for x in mcf1s_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_mcf1s, label=\"train_mcf1s\")\n",
    "plt.plot(val_mcf1s, label=\"val_mcf1s\")\n",
    "plt.title(\"F1 Macro\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"mcf1s score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704b582",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('transRVNet_torch.pt', weights_only=False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3028f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def expand_to_64(img):\n",
    "    N, C, H, W = img.shape\n",
    "    assert H == 16, \"A altura inicial da imagem deve ser 16.\"\n",
    "    expanded_img = torch.zeros((N, C, 64, W), device=img.device, dtype=img.dtype)\n",
    "    for i in range(H):\n",
    "        expanded_img[:, :, i * 4, :] = img[:, :, i, :]\n",
    "    return expanded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def reduce_to_16(img):\n",
    "    N, C, H, W = img.shape\n",
    "    assert H == 64, \"A altura da imagem deve ser 64 para ser reduzida para 16.\"\n",
    "    reduced_img = img.view(N, C, 16, 4, W).mean(dim=3)\n",
    "    return reduced_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5e7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(pred, label, mask, num_batch):\n",
    "    def to_numpy(tensor):\n",
    "        return tensor[0].detach().cpu().numpy()\n",
    "\n",
    "    scaling_values = {\n",
    "    \"x\" : {\"min\": -150., \"max\":150.},\n",
    "    \"y\" : {\"min\": -150., \"max\":150.},\n",
    "    \"z\" : {\"min\": -10., \"max\":30.},\n",
    "    \"r\" : {\"min\": 0., \"max\":1.},\n",
    "    \"d\" : {\"min\": 0., \"max\":130.}\n",
    "    }\n",
    "    \n",
    "    viz_tfm = ProjectionVizTransform(test_dataset.color_map_rgb_np, test_dataset.learning_map_inv_np, scaling_values)\n",
    "    pred_np = to_numpy(pred).argmax(0)\n",
    "    label_np = to_numpy(label)\n",
    "    mask_np = to_numpy(mask)\n",
    "\n",
    "    altered_pred_np = pred_np.copy()\n",
    "    # Set matching predictions to 0\n",
    "    altered_pred_np[altered_pred_np == label_np] = 0\n",
    "    \n",
    "    item = {\n",
    "        \"frame\": None,\n",
    "        \"label\": pred_np,\n",
    "        \"mask\": mask_np,\n",
    "        \"weight\": None\n",
    "    }\n",
    "    pred_img = viz_tfm(item)[\"label\"]\n",
    "\n",
    "    item[\"label\"] = altered_pred_np\n",
    "    altered_pred_img = viz_tfm(item)[\"label\"]\n",
    "    \n",
    "    item[\"label\"] = label_np\n",
    "    label_img = viz_tfm(item)[\"label\"]\n",
    "    \n",
    "    img_cmp = np.concatenate((label_img, altered_pred_img, pred_img), axis=0)\n",
    "    \n",
    "    img_cmp = img_cmp.astype(np.uint8)\n",
    "    img_cmp_pil = Image.fromarray(img_cmp)\n",
    "    save_path = f\"../../data/imgs/{num_batch}examples_with_loss.png\"\n",
    "    img_cmp_pil.save(save_path)\n",
    "     \n",
    "\n",
    "def inference_with_metrics(model, test_loader, device, i_type=None):\n",
    "    model.eval()\n",
    "\n",
    "    total_accuracy = 0\n",
    "    total_miou = 0\n",
    "    total_dice = 0\n",
    "    total_mcf1s = 0\n",
    "\n",
    "    first = 0\n",
    "    \n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\", leave=True):\n",
    "            num_batches += 1\n",
    "            test_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img = test_item['frame']\n",
    "            label = test_item['label'].to(torch.int64)\n",
    "            mask = test_item['mask']\n",
    "\n",
    "            label[~mask] = 0\n",
    "\n",
    "            xyz = img[:, :3, :, :]\n",
    "            depth = img[:, 3, :, :].unsqueeze(1)\n",
    "            reflectance = img[:, 4, :].unsqueeze(1)\n",
    "\n",
    "            #img = expand_to_64(img)\n",
    "            if i_type:\n",
    "                img = F.interpolate(img, size=(64,1024), mode=i_type)\n",
    "\n",
    "            pred = model(xyz, depth, reflectance)\n",
    "\n",
    "            if i_type:\n",
    "                #pred = pred[:, :, ::4, :]\n",
    "                pred = reduce_to_16(pred)\n",
    "            #pred = reduce_to_16(pred)\n",
    "            #pred = F.interpolate(pred.float(), size=(16,1024), mode='nearest')\n",
    "            \n",
    "            # if num_batches == 1:\n",
    "            #     print(f\"pred: {pred.shape}\\n mask: {mask.shape}\")\n",
    "                \n",
    "\n",
    "            if (num_batches % 1) == 0:\n",
    "                save_imgs(pred, label, mask, num_batches)\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "\n",
    "            current_test_acc = accuracy(pred_m, label_m)\n",
    "            current_test_miou = miou(pred_labels, label)\n",
    "            current_test_dice = dice(pred_labels, label)\n",
    "            current_test_mcf1s = mcf1s(pred_labels, label)\n",
    "\n",
    "            total_accuracy += current_test_acc\n",
    "            total_miou += current_test_miou\n",
    "            total_dice += current_test_dice\n",
    "            total_mcf1s += current_test_mcf1s\n",
    "\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "    avg_miou = total_miou / num_batches\n",
    "    avg_dice = total_dice / num_batches\n",
    "    avg_mcf1s = total_mcf1s / num_batches\n",
    "\n",
    "    return avg_accuracy, avg_miou, avg_dice, avg_mcf1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5063275",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_type = [\"normal\", \"bilinear\", \"nearest\"]\n",
    "classes = [\"unlabeled\", \"car\", \"person\", \"road\", \"terrain\", \"vegetation\"]\n",
    "for i_type in inference_type:\n",
    "    if i_type == \"normal\":\n",
    "        avg_acc, avg_miou, avg_dice, avg_f1_macro = inference_with_metrics(model, test_loader, device)\n",
    "    else:\n",
    "        avg_acc, avg_miou, avg_dice, avg_f1_macro = inference_with_metrics(model, test_loader, device, i_type)\n",
    "\n",
    "    print(i_type)\n",
    "    for iou, item in zip(avg_miou, classes):\n",
    "        print(f\"{item}: {iou*100:.1f}\")\n",
    "    mean = sum(avg_miou[1:6]/len(avg_miou[1:6]))\n",
    "    print(f\"\\nmean {mean*100:.1f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223f3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
