{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967697e7-371b-4ecc-8a32-20299f7498cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "255556ac-018a-4b5d-804c-0b08dc792f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorcloud.behley2019iccv import plot_projections\n",
    "from colorcloud.cheng2023TransRVNet import TransVRNet\n",
    "from colorcloud.cheng2023TransRVNet import TransRVNet_loss\n",
    "from colorcloud.cheng2023TransRVNet import RandomRotationTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomDroppingPointsTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomSingInvertingTransform\n",
    "from colorcloud.UFGsim2024infufg import ProjectionSimVizTransform\n",
    "from colorcloud.UFGsim2024infufg import UFGSimDataset\n",
    "from colorcloud.UFGsim2024infufg import UFGSimDataset\n",
    "from colorcloud.UFGsim2024infufg import SphericalProjection\n",
    "from colorcloud.UFGsim2024infufg import ProjectionSimTransform\n",
    "from colorcloud.UFGsim2024infufg import ProjectionToTensorTransformSim\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "from torchmetrics.classification import Dice\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fec74-752a-45cc-8094-a5dddc3accf6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eed986-4cf7-4ee2-a181-1a4f00679964",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57660195-b8be-45ea-82d4-ac361abb8612",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convolutions' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6686904-8719-4759-b840-e6204f25860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrciam_p = {\n",
    "    \"p1\": {\n",
    "        \"b1_in\": 1,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"p2\": {\n",
    "        \"b1_in\": 3,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"output_conv\": 192\n",
    "}\n",
    "encoder_p = {\n",
    "    \"module_1\": {\n",
    "        \"in_channels\": 192,\n",
    "        \"conv2_in_channels\": 128,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    },\n",
    "    \"module_2\": {\n",
    "        \"in_channels\": 256,\n",
    "        \"conv2_in_channels\": 256,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    }\n",
    "}\n",
    "\n",
    "decoder_p = {\n",
    "    \"in_channels\": 264,\n",
    "    \"conv2_in_channels\": 128,\n",
    "    \"dilated_conv_in_channels\": 128,\n",
    "    \"dilated_conv_out_channels\": 64,\n",
    "    \"output\": 32\n",
    "}\n",
    "\n",
    "p_bntm = {\n",
    "    \"window_size\": (4,4),\n",
    "    \"embed_dim\": int(encoder_p[\"module_2\"][\"residual_out_channels\"]/8)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cff5f-ad7b-4922-92aa-c81fede806e9",
   "metadata": {},
   "source": [
    "## Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = SphericalProjection(fov_up_deg=15., fov_down_deg=-15., W=440, H=16)\n",
    "\n",
    "aug_tfms = v2.Compose([\n",
    "    RandomDroppingPointsTransform(),\n",
    "    RandomRotationTransform(),\n",
    "    RandomSingInvertingTransform(),\n",
    "    ProjectionSimTransform(proj),\n",
    "    ProjectionToTensorTransformSim(),\n",
    "])\n",
    "\n",
    "data_path = '/workspace/data'\n",
    "train_dataset = UFGSimDataset(data_path=data_path, split='train', transform=aug_tfms)\n",
    "val_dataset = UFGSimDataset(data_path=data_path, split='valid', transform=aug_tfms)\n",
    "\n",
    "print(\"Size of train dataset: \", len(train_dataset))\n",
    "print(\"Size of val dataset: \", len(val_dataset))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0].keys())\n",
    "print(train_dataset[0]['frame'].shape, train_dataset[0]['frame'].dtype)\n",
    "print(train_dataset[0]['label'].shape, train_dataset[0]['label'].dtype)\n",
    "print(train_dataset[0]['mask'].shape, train_dataset[0]['mask'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps\n",
    "n_epochs = 50\n",
    "train_steps = len(train_loader) // batch_size\n",
    "test_steps = len(val_loader) // batch_size\n",
    "total_steps = train_steps * n_epochs\n",
    "H = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "\n",
    "model = TransVRNet(mrciam_p, encoder_p, decoder_p, p_bntm, using_reflectance=False).to(device)\n",
    "# loss function\n",
    "loss_func = TransRVNet_loss(device=device, file_name_yaml='ufg-sim.yaml')\n",
    "# optimizer\n",
    "opt = AdamW(model.parameters(), lr=5e-4, eps=1e-5, weight_decay=0.0001)\n",
    "lr_scheduler = OneCycleLR(opt, max_lr=0.002, div_factor=1, final_div_factor=10, steps_per_epoch=total_steps, epochs=30)\n",
    "# dropout\n",
    "dropout = torch.nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "\n",
    "# metrics\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=model.n_classes).to(device)\n",
    "accuracy_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "miou = MeanIoU(num_classes=model.n_classes).to(device)\n",
    "miou_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "dice = Dice(num_classes=model.n_classes).to(device)\n",
    "dice_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "mcf1s = MulticlassF1Score(num_classes=model.n_classes, average=\"macro\").to(device)\n",
    "mcf1s_dict = {\"train\": [], \"val\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epochs in tqdm(range(n_epochs)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "        img, label, mask = train_item['frame'], train_item['label'], train_item['mask']\n",
    "\n",
    "        # Separate channels\n",
    "        xyz = img[:, :3, :, :]\n",
    "        print(img.shape, img.dtype)\n",
    "        # passando so um tensor do shape esperado pela reflectancia, mesmo nao sendo utilizada no modelo\n",
    "        reflectance = img[:, 3, :, :].unsqueeze(1)\n",
    "        depth = img[:, 3, :, :].unsqueeze(1)\n",
    "\n",
    "        print('label: ', label.shape)\n",
    "\n",
    "        pred = model(reflectance, depth, xyz)\n",
    "\n",
    "        print('pred: ', pred.shape)\n",
    "\n",
    "        # Apply dropout\n",
    "        pred = dropout(pred)\n",
    "\n",
    "        label[~mask] = 0\n",
    "        train_loss = loss_func(pred, label, mask)\n",
    "\n",
    "        pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "        pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "        mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "        pred_m = pred_f[mask_f, :]\n",
    "        label_m = label[mask]\n",
    "\n",
    "        current_train_acc = accuracy(pred_m, label_m)\n",
    "        accuracy_dict[\"train\"].append(current_train_acc)\n",
    "        pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "        mask_miou = (label != 0)\n",
    "        pred_labels[~mask] = 0\n",
    "        current_train_miou = miou(pred_labels, label)\n",
    "        miou_dict[\"train\"].append(current_train_miou)\n",
    "        current_train_dice = dice(pred_labels, label)\n",
    "        dice_dict[\"train\"].append(current_train_dice)\n",
    "        current_train_mcf1s = mcf1s(pred_labels, label)\n",
    "        mcf1s_dict[\"train\"].append(current_train_mcf1s)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in val_loader:\n",
    "            test_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img, label, mask = train_item['frame'], train_item['label'], train_item['mask']\n",
    "    \n",
    "            # Separate channels\n",
    "            xyz = img[:, :3, :, :]\n",
    "            depth = img[:, 3, :, :].unsqueeze(1)\n",
    "\n",
    "            pred = model(depth, depth, xyz)\n",
    "\n",
    "            label[~mask] = 0\n",
    "            test_loss = loss_func(pred, label, mask)\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "\n",
    "            current_test_acc = accuracy(pred_m, label_m)\n",
    "            accuracy_dict[\"val\"].append(current_test_acc)\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "            current_test_miou = miou(pred_labels, label)\n",
    "            miou_dict[\"val\"].append(current_test_miou)\n",
    "            current_test_dice = dice(pred_labels, label)\n",
    "            dice_dict[\"val\"].append(current_test_dice)\n",
    "            current_test_mcf1s = mcf1s(pred_labels, label)\n",
    "            mcf1s_dict[\"val\"].append(current_test_mcf1s)\n",
    "        \n",
    "            total_test_loss += test_loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_test_loss = total_test_loss / test_steps\n",
    "\n",
    "    # Store loss history for graphical visualization\n",
    "    H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
    "\n",
    "    print(\"CURRENT EPOCH: {}/{}\".format(epochs + 1, n_epochs))\n",
    "    print(\"Train loss: {:.10f}, Test loss {:.4f}\".format(avg_train_loss, avg_test_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training took {:.2f}s\".format(end_time - start_time))\n",
    "print(\"Accuracy: {:.4f} on training and {:.4f} on testing\".format(current_train_acc, current_test_acc))\n",
    "print(\"Mean IOU: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"Dice: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"F1 Macro: {:.4f} on training and {:.4f} on testing\".format(current_train_mcf1s, current_test_mcf1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = \"ufgsim_transRVNet_torch.pt\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f596aa",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "train_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"train\"]]\n",
    "val_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "train_miou = [x.cpu().numpy() for x in miou_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_miou, label=\"train_miou\")\n",
    "plt.plot(val_miou, label=\"val_miou\")\n",
    "plt.title(\"Mean IOU\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"miou\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice\n",
    "train_dice = [x.cpu().numpy() for x in dice_dict[\"train\"]]\n",
    "val_dice = [x.cpu().numpy() for x in dice_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_dice, label=\"train_dice\")\n",
    "plt.plot(val_dice, label=\"val_dice\")\n",
    "plt.title(\"Dice\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"dice score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b54ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Macro\n",
    "train_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"train\"]]\n",
    "val_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_mcf1s, label=\"train_mcf1s\")\n",
    "plt.plot(val_mcf1s, label=\"val_mcf1s\")\n",
    "plt.title(\"F1 Macro\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"mcf1s score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704b582",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25bd60d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransVRNet(\n",
       "  (mrciam): MRCIAM(\n",
       "    (mrciam_depth_reflectance): MRCIAMSingleChannel(\n",
       "      (block1_3x3): ConvBNPReLU(\n",
       "        (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_5x5): ConvBNPReLU(\n",
       "        (conv): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_7x7): ConvBNPReLU(\n",
       "        (conv): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_3x3_2): ConvBNPReLU(\n",
       "        (conv): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_1x1): ConvBNPReLU(\n",
       "        (conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block2_3x3): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block2_3x3_dilated): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block2_1x1): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_3x3): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_5x5): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_7x7): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_3x3_2): ConvBNPReLU(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_1x1): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (sac_block): SACBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (gn): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (mrciam_xyz): MRCIAMSingleChannel(\n",
       "      (block1_3x3): ConvBNPReLU(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_5x5): ConvBNPReLU(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_7x7): ConvBNPReLU(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_3x3_2): ConvBNPReLU(\n",
       "        (conv): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block1_1x1): ConvBNPReLU(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block2_3x3): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block2_3x3_dilated): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block2_1x1): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_3x3): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_5x5): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_7x7): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_3x3_2): ConvBNPReLU(\n",
       "        (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (block3_1x1): ConvBNPReLU(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (sac_block): SACBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (gn): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_1x1): ConvBNPReLU(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (sac_block): SACBlock(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (gn): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_module1): EncoderModule(\n",
       "    (encoder_block): BasicEncoderBlock(\n",
       "      (conv1): ConvBNPReLU(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv2): ConvBNPReLU(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (dilated_conv): ConvBNPReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (residual_conv1): ConvBNPReLU(\n",
       "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (residual_conv2): ConvBNPReLU(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (cam): CAM(\n",
       "      (pool): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)\n",
       "      (Conv2d): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (Conv2d_2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (avg_pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "  )\n",
       "  (encoder_module2): EncoderModule(\n",
       "    (encoder_block): BasicEncoderBlock(\n",
       "      (conv1): ConvBNPReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv2): ConvBNPReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (dilated_conv): ConvBNPReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (residual_conv1): ConvBNPReLU(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (residual_conv2): ConvBNPReLU(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (cam): CAM(\n",
       "      (pool): MaxPool2d(kernel_size=7, stride=1, padding=3, dilation=1, ceil_mode=False)\n",
       "      (Conv2d): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (Conv2d_2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (avg_pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (bntm): SwinTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0): BNTM(\n",
       "          (blocks): ModuleList(\n",
       "            (0-3): 4 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): BNTM(\n",
       "          (blocks): ModuleList(\n",
       "            (0-3): 4 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): BNTM(\n",
       "          (blocks): ModuleList(\n",
       "            (0-3): 4 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): BNTM(\n",
       "          (blocks): ModuleList(\n",
       "            (0-3): 4 x SwinTransformerBlock(\n",
       "              (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): WindowAttention(\n",
       "                (qkv): Linear(in_features=32, out_features=96, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): MLP(\n",
       "                (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "                (drop): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (redduce1): Linear(in_features=320, out_features=128, bias=False)\n",
       "      (redduce2): Linear(in_features=288, out_features=64, bias=False)\n",
       "      (redduce3): Linear(in_features=272, out_features=32, bias=False)\n",
       "      (norm512): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm256): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm128): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm64): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (upsample): PixelShuffle(upscale_factor=2)\n",
       "    (conv_decoder_block): ConvDecoderBlock(\n",
       "      (conv_3x3_1): ConvBNPReLU(\n",
       "        (conv): Conv2d(264, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_3x3_2): ConvBNPReLU(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (dilated_conv): ConvBNPReLU(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (conv_1x1): ConvBNPReLU(\n",
       "        (conv): Conv2d(384, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (seg_head): ConvBNPReLU(\n",
       "      (conv): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('ufgsim_transRVNet_torch.pt', weights_only=False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "375dbd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 440) bool\n",
      "(16, 440) int64\n",
      "(13,)\n",
      "(16, 440, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = []\n",
    "item = None\n",
    "learning_map_inv_np = val_dataset.learning_map_inv_np\n",
    "color_map_rgb_np = val_dataset.color_map_rgb_np\n",
    "\n",
    "color_pred = None\n",
    "\n",
    "channels=['x', 'y', 'z']\n",
    "channels_map = {\"x\": 0, \"y\": 1, \"z\": 2, \"d\": 3}\n",
    "num_channels = len(channels)\n",
    "fig_size_vertical = 2*num_channels\n",
    "\n",
    "for batch in val_loader:\n",
    "    train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "    img, label, m = train_item['frame'], train_item['label'], train_item['mask']\n",
    "\n",
    "    mask = m.cpu().squeeze(0).detach().numpy()\n",
    "    item = train_item\n",
    "\n",
    "    cpuimg = img.cpu()\n",
    "    # Separate channels\n",
    "    xyz = img[:, :3, :, :]\n",
    "    depth = img[:, 3, :, :].unsqueeze(1)\n",
    "\n",
    "    p = torch.argmax(model(depth, depth, xyz).cpu(), dim=1).squeeze(0).detach().numpy()\n",
    "\n",
    "    print(mask.shape, mask.dtype)\n",
    "    print(p.shape, p.dtype)\n",
    "    print(learning_map_inv_np.shape)\n",
    "\n",
    "    valid_indices = np.clip(p[mask], 0, len(learning_map_inv_np) - 1)\n",
    "    p[mask] = learning_map_inv_np[valid_indices]\n",
    "    colored_label_img = np.zeros(p.shape + (3,))\n",
    "    colored_label_img[mask] = color_map_rgb_np[p[mask]]\n",
    "    colored_label_img = colored_label_img.astype(int)\n",
    "\n",
    "    color_pred = colored_label_img\n",
    "\n",
    "    print(color_pred.shape)\n",
    "    item['label'] = p\n",
    "    # pred.append(torch.argmax(model(depth, depth, xyz).cpu().squeeze(0), dim=0))\n",
    "    plot_projections(cpuimg[0].data, color_pred, channels=['x'], channels_map=channels_map)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b58cc990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_projections(cpuimg[0].data, color_pred, channels=['x'], channels_map=channels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9af88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
