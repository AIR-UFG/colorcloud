{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967697e7-371b-4ecc-8a32-20299f7498cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255556ac-018a-4b5d-804c-0b08dc792f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from colorcloud.behley2019iccv import plot_projections\n",
    "from colorcloud.cheng2023TransRVNet import TransVRNet\n",
    "from colorcloud.cheng2023TransRVNet import TransRVNet_loss\n",
    "from colorcloud.cheng2023TransRVNet import RandomRotationTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomDroppingPointsTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomSingInvertingTransform\n",
    "from colorcloud.behley2019iccv import SemanticKITTIDataset\n",
    "from colorcloud.behley2019iccv import ProjectionTransform\n",
    "from colorcloud.behley2019iccv import ProjectionToTensorTransform\n",
    "from colorcloud.behley2019iccv import SphericalProjection\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "from torchmetrics.classification import Dice\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fec74-752a-45cc-8094-a5dddc3accf6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6eed986-4cf7-4ee2-a181-1a4f00679964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57660195-b8be-45ea-82d4-ac361abb8612",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convolutions' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6686904-8719-4759-b840-e6204f25860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrciam_p = {\n",
    "    \"p1\": {\n",
    "        \"b1_in\": 1,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"p2\": {\n",
    "        \"b1_in\": 3,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"output_conv\": 192\n",
    "}\n",
    "encoder_p = {\n",
    "    \"module_1\": {\n",
    "        \"in_channels\": 192,\n",
    "        \"conv2_in_channels\": 128,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    },\n",
    "    \"module_2\": {\n",
    "        \"in_channels\": 256,\n",
    "        \"conv2_in_channels\": 256,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    }\n",
    "}\n",
    "\n",
    "decoder_p = {\n",
    "    \"in_channels\": 264,\n",
    "    \"conv2_in_channels\": 128,\n",
    "    \"dilated_conv_in_channels\": 128,\n",
    "    \"dilated_conv_out_channels\": 64,\n",
    "    \"output\": 32\n",
    "}\n",
    "\n",
    "p_bntm = {\n",
    "    \"window_size\": (4,4),\n",
    "    \"embed_dim\": int(encoder_p[\"module_2\"][\"residual_out_channels\"]/8)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cff5f-ad7b-4922-92aa-c81fede806e9",
   "metadata": {},
   "source": [
    "## Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c202e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset:  1229\n",
      "Size of val dataset:  709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/colorcloud/colorcloud/behley2019iccv.py:58: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.content_weights = 1./content_sum_np\n"
     ]
    }
   ],
   "source": [
    "proj = SphericalProjection(fov_up_deg=15., fov_down_deg=-15., W=1024, H=16)\n",
    "scaling_values = {\n",
    "    \"x\" : {\"min\": -150., \"max\":150.},\n",
    "    \"y\" : {\"min\": -150., \"max\":150.},\n",
    "    \"z\" : {\"min\": -10., \"max\":30.},\n",
    "    \"r\" : {\"min\": 0., \"max\":1.},\n",
    "    \"d\" : {\"min\": 0., \"max\":130.}\n",
    "}\n",
    "data_path = '/workspace/data'\n",
    "train_dataset = SemanticKITTIDataset(data_path=data_path, split='train', ufg_dataset=True)\n",
    "val_dataset = SemanticKITTIDataset(data_path=data_path, split='valid', ufg_dataset=True)\n",
    "\n",
    "aug_tfms = v2.Compose([\n",
    "    RandomDroppingPointsTransform(),\n",
    "    RandomRotationTransform(),\n",
    "    RandomSingInvertingTransform(),\n",
    "    ProjectionTransform(proj),\n",
    "ProjectionToTensorTransform(),\n",
    "])\n",
    "\n",
    "train_dataset.set_transform(aug_tfms)\n",
    "val_dataset.set_transform(aug_tfms)\n",
    "\n",
    "print(\"Size of train dataset: \", len(train_dataset))\n",
    "print(\"Size of val dataset: \", len(val_dataset))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7e8b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['frame', 'label', 'mask'])\n",
      "torch.Size([5, 16, 1024]) torch.float32\n",
      "torch.Size([16, 1024]) torch.int32\n",
      "torch.Size([16, 1024]) torch.bool\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0].keys())\n",
    "print(train_dataset[0]['frame'].shape, train_dataset[0]['frame'].dtype)\n",
    "print(train_dataset[0]['label'].shape, train_dataset[0]['label'].dtype)\n",
    "print(train_dataset[0]['mask'].shape, train_dataset[0]['mask'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a193e990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/colorcloud/colorcloud/cheng2023TransRVNet.py:883: RuntimeWarning: invalid value encountered in divide\n",
      "  class_weights = (median_freq / frequencies) ** exponent\n"
     ]
    }
   ],
   "source": [
    "# steps\n",
    "n_epochs = 5\n",
    "train_steps = len(train_loader) // batch_size\n",
    "test_steps = len(val_loader) // batch_size\n",
    "total_steps = train_steps * n_epochs\n",
    "H = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "\n",
    "model = TransVRNet(mrciam_p, encoder_p, decoder_p, p_bntm, using_reflectance=True, ufg_format=True).to(device)\n",
    "# loss function\n",
    "loss_func = TransRVNet_loss(device=device, file_name_yaml='semantic-kitti.yaml')\n",
    "# optimizer\n",
    "opt = AdamW(model.parameters(), lr=5e-4, eps=1e-5, weight_decay=0.0001)\n",
    "lr_scheduler = OneCycleLR(opt, max_lr=0.002, div_factor=1, final_div_factor=10, steps_per_epoch=total_steps, epochs=30)\n",
    "# dropout\n",
    "dropout = torch.nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "\n",
    "# metrics\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=model.n_classes).to(device)\n",
    "accuracy_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "miou = MeanIoU(num_classes=model.n_classes).to(device)\n",
    "miou_dict = {\"train\": [], \"val\": []}\n",
    "miou_per_class = MeanIoU(num_classes=model.n_classes, per_class=True).to(device)\n",
    "miou_per_class_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "dice = Dice(num_classes=model.n_classes).to(device)\n",
    "dice_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "mcf1s = MulticlassF1Score(num_classes=model.n_classes, average=\"macro\").to(device)\n",
    "mcf1s_dict = {\"train\": [], \"val\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b2d8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 1024]) tensor([[[17,  4,  4,  ..., 14,  5,  5],\n",
      "         [18, 16,  2,  ..., 17,  1, 17],\n",
      "         [13, 10,  0,  ...,  9, 18, 18],\n",
      "         ...,\n",
      "         [ 1,  7,  2,  ..., 17, 18, 17],\n",
      "         [ 2,  6, 17,  ...,  8, 17,  4],\n",
      "         [18,  4, 10,  ..., 10, 18, 17]]], device='cuda:0')\n",
      "torch.Size([1, 16, 1024]) tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [3, 3, 3,  ..., 3, 3, 3],\n",
      "         [0, 3, 3,  ..., 0, 3, 0]]], device='cuda:0', dtype=torch.int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m pred_labels[\u001b[38;5;241m~\u001b[39mmask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(label\u001b[38;5;241m.\u001b[39mshape, label)\n\u001b[0;32m---> 44\u001b[0m current_train_miou \u001b[38;5;241m=\u001b[39m \u001b[43mmiou\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m miou_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(current_train_miou)\n\u001b[1;32m     46\u001b[0m current_train_miou_per_class \u001b[38;5;241m=\u001b[39m miou_per_class(pred_labels, label)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:311\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:380\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:492\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    486\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device corresponds to the device of the input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_cpu:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_list_states_to_cpu()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/metric.py:482\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/segmentation/mean_iou.py:111\u001b[0m, in \u001b[0;36mMeanIoU.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the state with the new data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     intersection, union \u001b[38;5;241m=\u001b[39m \u001b[43m_mean_iou_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_background\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     score \u001b[38;5;241m=\u001b[39m _mean_iou_compute(intersection, union, per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mper_class)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mper_class \u001b[38;5;28;01melse\u001b[39;00m score\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchmetrics/functional/segmentation/mean_iou.py:50\u001b[0m, in \u001b[0;36m_mean_iou_update\u001b[0;34m(preds, target, num_classes, include_background)\u001b[0m\n\u001b[1;32m     48\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(preds, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mmovedim(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (target\u001b[38;5;241m.\u001b[39mbool() \u001b[38;5;241m!=\u001b[39m target)\u001b[38;5;241m.\u001b[39many():  \u001b[38;5;66;03m# target is an index tensor\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmovedim(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_background:\n\u001b[1;32m     53\u001b[0m     preds, target \u001b[38;5;241m=\u001b[39m _ignore_background(preds, target)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "from re import X\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epochs in tqdm(range(n_epochs)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "        img, label, mask = train_item['frame'], train_item['label'], train_item['mask']\n",
    "\n",
    "        # Separate channels\n",
    "        xyz = img[:, :3, :, :]\n",
    "        # passando so um tensor do shape esperado pela reflectancia, mesmo nao sendo utilizada no modelo\n",
    "        reflectance = img[:, 3, :, :].unsqueeze(1)\n",
    "        depth = img[:, 4, :, :].unsqueeze(1)        \n",
    "\n",
    "        pred = model(xyz, depth, reflectance)\n",
    "\n",
    "        # Apply dropout\n",
    "        pred = dropout(pred)\n",
    "\n",
    "        label[~mask] = 0\n",
    "        train_loss = loss_func(pred, label, mask)\n",
    "\n",
    "        pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "        pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "        mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "        pred_m = pred_f[mask_f, :]\n",
    "        label_m = label[mask]\n",
    "\n",
    "        current_train_acc = accuracy(pred_m, label_m)\n",
    "        accuracy_dict[\"train\"].append(current_train_acc)\n",
    "        pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "        mask_miou = (label != 0)\n",
    "        print(pred_labels.shape, pred_labels)\n",
    "        pred_labels[~mask] = 0\n",
    "        print(label.shape, label)\n",
    "        current_train_miou = miou(pred_labels, label)\n",
    "        miou_dict[\"train\"].append(current_train_miou)\n",
    "        current_train_miou_per_class = miou_per_class(pred_labels, label)\n",
    "        miou_per_class_dict[\"train\"].append(current_train_miou_per_class)\n",
    "        current_train_dice = dice(pred_labels, label)\n",
    "        dice_dict[\"train\"].append(current_train_dice)\n",
    "        current_train_mcf1s = mcf1s(pred_labels, label)\n",
    "        mcf1s_dict[\"train\"].append(current_train_mcf1s)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in val_loader:\n",
    "            test_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img, label, mask = train_item['frame'], train_item['label'], train_item['mask']\n",
    "    \n",
    "            # Separate channels\n",
    "            xyz = img[:, :3, :, :]\n",
    "            depth = img[:, 3, :, :].unsqueeze(1)\n",
    "            reflectance = img[:, 4, :].unsqueeze(1)\n",
    "\n",
    "            pred = model(xyz, depth, reflectance)\n",
    "\n",
    "            label[~mask] = 0\n",
    "\n",
    "            test_loss = loss_func(pred, label, mask)\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "\n",
    "            current_test_acc = accuracy(pred_m, label_m)\n",
    "            accuracy_dict[\"val\"].append(current_test_acc)\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "            current_test_miou = miou(pred_labels, label)\n",
    "            miou_dict[\"val\"].append(current_test_miou)\n",
    "            current_train_miou_per_class = miou_per_class(pred_labels, label)\n",
    "            miou_per_class_dict[\"val\"].append(current_train_miou_per_class)\n",
    "            current_test_dice = dice(pred_labels, label)\n",
    "            dice_dict[\"val\"].append(current_test_dice)\n",
    "            current_test_mcf1s = mcf1s(pred_labels, label)\n",
    "            mcf1s_dict[\"val\"].append(current_test_mcf1s)\n",
    "        \n",
    "            total_test_loss += test_loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_test_loss = total_test_loss / test_steps\n",
    "\n",
    "    # Store loss history for graphical visualization\n",
    "    H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
    "\n",
    "    print(\"CURRENT EPOCH: {}/{}\".format(epochs + 1, n_epochs))\n",
    "    print(\"Train loss: {:.10f}, Test loss {:.4f}\".format(avg_train_loss, avg_test_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training took {:.2f}s\".format(end_time - start_time))\n",
    "print(\"Accuracy: {:.4f} on training and {:.4f} on testing\".format(current_train_acc, current_test_acc))\n",
    "print(\"Mean IOU: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"Dice: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"F1 Macro: {:.4f} on training and {:.4f} on testing\".format(current_train_mcf1s, current_test_mcf1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = \"ufgsim_transRVNet_torch.pt\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f596aa",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "train_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"train\"]]\n",
    "val_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "train_miou = [x.cpu().numpy() for x in miou_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_miou, label=\"train_miou\")\n",
    "plt.plot(val_miou, label=\"val_miou\")\n",
    "plt.title(\"Mean IOU\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"miou\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU per class\n",
    "train_miou = [x.cpu().numpy() for x in miou_per_class_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_per_class_dict[\"val\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "mean_train_miou = np.mean(train_miou, axis=0)\n",
    "mean_val_miou = np.mean(val_miou, axis=0)\n",
    "\n",
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "mean_train_miou = mean_train_miou[:13]\n",
    "mean_val_miou = mean_val_miou[:13]\n",
    "\n",
    "# Número de classes\n",
    "num_classes = mean_train_miou.shape[0]\n",
    "classes = [f'Classe {i+1}' for i in range(num_classes)]\n",
    "\n",
    "# Plotando o gráfico de barras para Mean IoU de treino e validação\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(num_classes)\n",
    "\n",
    "# Barras para treino e validação\n",
    "plt.bar(index, mean_train_miou, bar_width, label='Treino', color='salmon', edgecolor='black')\n",
    "plt.bar(index + bar_width, mean_val_miou, bar_width, label='Validação', color='skyblue', edgecolor='black')\n",
    "\n",
    "# Configuração dos eixos e títulos\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.title('Mean IoU Médio por Classe para Treino e Validação')\n",
    "plt.xticks(index + bar_width / 2, classes, rotation=45)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte as listas de arrays para arrays 2D para cada variável\n",
    "train_miou = np.array(train_miou)\n",
    "val_miou = np.array(val_miou)\n",
    "\n",
    "# Calcula a média do Mean IoU por classe para o conjunto de treino e validação\n",
    "mean_train_miou = np.mean(train_miou, axis=0)\n",
    "mean_val_miou = np.mean(val_miou, axis=0)\n",
    "\n",
    "# Plotando os histogramas para os vetores médios de Mean IoU de treino e validação\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histograma do conjunto de treino\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(mean_train_miou, bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Histograma do Mean IoU Médio por Classe (Treino)')\n",
    "plt.xlabel('Mean IoU')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Histograma do conjunto de validação\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mean_val_miou, bins=10, color='salmon', edgecolor='black')\n",
    "plt.title('Histograma do Mean IoU Médio por Classe (Validação)')\n",
    "plt.xlabel('Mean IoU')\n",
    "plt.ylabel('Frequência')\n",
    "\n",
    "# Ajusta o layout e exibe o gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice\n",
    "train_dice = [x.cpu().numpy() for x in dice_dict[\"train\"]]\n",
    "val_dice = [x.cpu().numpy() for x in dice_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_dice, label=\"train_dice\")\n",
    "plt.plot(val_dice, label=\"val_dice\")\n",
    "plt.title(\"Dice\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"dice score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b54ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Macro\n",
    "train_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"train\"]]\n",
    "val_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_mcf1s, label=\"train_mcf1s\")\n",
    "plt.plot(val_mcf1s, label=\"val_mcf1s\")\n",
    "plt.title(\"F1 Macro\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"mcf1s score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704b582",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('ufgsim_transRVNet_torch.pt', weights_only=False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375dbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "item = None\n",
    "learning_map_inv_np = val_dataset.learning_map_inv_np\n",
    "color_map_rgb_np = val_dataset.color_map_rgb_np\n",
    "\n",
    "color_pred = None\n",
    "\n",
    "channels=['x', 'y', 'z']\n",
    "channels_map = {\"x\": 0, \"y\": 1, \"z\": 2, \"d\": 3}\n",
    "num_channels = len(channels)\n",
    "fig_size_vertical = 2*num_channels\n",
    "\n",
    "for batch in val_loader:\n",
    "    train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "    img, label, m = train_item['frame'], train_item['label'], train_item['mask']\n",
    "\n",
    "    mask = m.cpu().squeeze(0).detach().numpy()\n",
    "    item = train_item\n",
    "\n",
    "    cpuimg = img.cpu()\n",
    "    # Separate channels\n",
    "    xyz = img[:, :3, :, :]\n",
    "    depth = img[:, 3, :, :].unsqueeze(1)\n",
    "\n",
    "    p = torch.argmax(model(depth, depth, xyz).cpu(), dim=1).squeeze(0).detach().numpy()\n",
    "\n",
    "    print(mask.shape, mask.dtype)\n",
    "    print(p.shape, p.dtype)\n",
    "    print(learning_map_inv_np.shape)\n",
    "\n",
    "    valid_indices = np.clip(p[mask], 0, len(learning_map_inv_np) - 1)\n",
    "    p[mask] = learning_map_inv_np[valid_indices]\n",
    "    colored_label_img = np.zeros(p.shape + (3,))\n",
    "    colored_label_img[mask] = color_map_rgb_np[p[mask]]\n",
    "    colored_label_img = colored_label_img.astype(int)\n",
    "\n",
    "    color_pred = colored_label_img\n",
    "\n",
    "    print(color_pred.shape)\n",
    "    item['label'] = p\n",
    "    # pred.append(torch.argmax(model(depth, depth, xyz).cpu().squeeze(0), dim=0))\n",
    "    # plot_projections(cpuimg[0].data, color_pred, channels=['x'], channels_map=channels_map)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_projections(cpuimg[0].data, color_pred, channels=['x'], channels_map=channels_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
