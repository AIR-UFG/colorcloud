{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967697e7-371b-4ecc-8a32-20299f7498cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "255556ac-018a-4b5d-804c-0b08dc792f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorcloud.cheng2023TransRVNet import TransVRNet\n",
    "from colorcloud.cheng2023TransRVNet import SemanticSegmentationTask\n",
    "from colorcloud.cheng2023TransRVNet import TransRVNet_loss\n",
    "from colorcloud.cheng2023TransRVNet import RandomRotationTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomDroppingPointsTransform\n",
    "from colorcloud.cheng2023TransRVNet import RandomSingInvertingTransform\n",
    "from colorcloud.UFGsim2024infufg import SemanticSegmentationSimLDM\n",
    "from colorcloud.UFGsim2024infufg import ProjectionSimVizTransform\n",
    "from colorcloud.UFGsim2024infufg import UFGSimDataset\n",
    "from colorcloud.UFGsim2024infufg import UFGSimDataset\n",
    "from colorcloud.UFGsim2024infufg import SphericalProjection\n",
    "from colorcloud.UFGsim2024infufg import ProjectionSimTransform\n",
    "from colorcloud.UFGsim2024infufg import ProjectionToTensorTransformSim\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "from torchmetrics.classification import Dice\n",
    "from torchmetrics.classification import MulticlassF1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fec74-752a-45cc-8094-a5dddc3accf6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6eed986-4cf7-4ee2-a181-1a4f00679964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57660195-b8be-45ea-82d4-ac361abb8612",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convolutions' Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6686904-8719-4759-b840-e6204f25860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrciam_p = {\n",
    "    \"p1\": {\n",
    "        \"b1_in\": 1,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"p2\": {\n",
    "        \"b1_in\": 3,\n",
    "        \"b1_out1\": 32,\n",
    "        \"b1_out2\": 32,\n",
    "        \"b1_out3\": 32,\n",
    "        \"b2_in\": 64,\n",
    "        \"b2_out\": 64,\n",
    "        \"b3_in\": 64,\n",
    "        \"b3_out1\": 64,\n",
    "        \"b3_out2\": 64,\n",
    "        \"b3_out3\": 64,\n",
    "        \"output\": 64,\n",
    "    },\n",
    "    \"output_conv\": 192\n",
    "}\n",
    "encoder_p = {\n",
    "    \"module_1\": {\n",
    "        \"in_channels\": 192,\n",
    "        \"conv2_in_channels\": 128,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    },\n",
    "    \"module_2\": {\n",
    "        \"in_channels\": 256,\n",
    "        \"conv2_in_channels\": 256,\n",
    "        \"conv2_out_channels\": 256,\n",
    "        \"dilated_conv_out_channels\": 256,\n",
    "        \"residual_out_channels\": 256\n",
    "    }\n",
    "}\n",
    "\n",
    "decoder_p = {\n",
    "    \"in_channels\": 264,\n",
    "    \"conv2_in_channels\": 128,\n",
    "    \"dilated_conv_in_channels\": 128,\n",
    "    \"dilated_conv_out_channels\": 64,\n",
    "    \"output\": 32\n",
    "}\n",
    "\n",
    "p_bntm = {\n",
    "    \"window_size\": (4,4),\n",
    "    \"embed_dim\": int(encoder_p[\"module_2\"][\"residual_out_channels\"]/8)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cff5f-ad7b-4922-92aa-c81fede806e9",
   "metadata": {},
   "source": [
    "## Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c202e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset:  330\n",
      "Size of val dataset:  151\n"
     ]
    }
   ],
   "source": [
    "proj = SphericalProjection(fov_up_deg=15., fov_down_deg=-15., W=440, H=16)\n",
    "\n",
    "aug_tfms = v2.Compose([\n",
    "    RandomDroppingPointsTransform(),\n",
    "    RandomRotationTransform(),\n",
    "    RandomSingInvertingTransform(),\n",
    "])\n",
    "\n",
    "# tfms = v2.Compose([\n",
    "#     ProjectionSimTransform(proj),\n",
    "#     ProjectionToTensorTransformSim(),\n",
    "# ])\n",
    "\n",
    "data_path = '/workspace/data'\n",
    "train_dataset = UFGSimDataset(data_path=data_path, split='train', transform=tfms)\n",
    "val_dataset = UFGSimDataset(data_path=data_path, split='valid', transform=tfms)\n",
    "\n",
    "print(\"Size of train dataset: \", len(train_dataset))\n",
    "print(\"Size of val dataset: \", len(val_dataset))\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a193e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "model = TransVRNet(mrciam_p, encoder_p, decoder_p, p_bntm).to(device)\n",
    "loss_fn = TransRVNet_loss(device=device, file_name_yaml='ufg-sim.yaml')\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "opt = AdamW(model.parameters(), lr=5e-4, eps=1e-5)\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=model.n_classes).to(device)\n",
    "accuracy_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "miou = MeanIoU(num_classes=model.n_classes).to(device)\n",
    "miou_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "dice = Dice(num_classes=model.n_classes).to(device)\n",
    "dice_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "mcf1s = MulticlassF1Score(num_classes=model.n_classes, average=\"macro\").to(device)\n",
    "mcf1s_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "train_steps = len(train_loader) // batch_size\n",
    "test_steps = len(val_loader) // batch_size\n",
    "H = {\"train_loss\": [], \"test_loss\": []} # store loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2d8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TransVRNet.forward() missing 2 required positional arguments: 'x2' and 'x3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m mask \u001b[38;5;241m=\u001b[39m train_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m label[\u001b[38;5;241m~\u001b[39mmask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_func(pred, label)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TransVRNet.forward() missing 2 required positional arguments: 'x2' and 'x3'"
     ]
    }
   ],
   "source": [
    "tart_time = time.time()\n",
    "\n",
    "for epochs in tqdm(range(n_epochs)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "        img = train_item['frame']\n",
    "        label = train_item['label']\n",
    "        mask = train_item['mask']\n",
    "\n",
    "        label[~mask] = 0\n",
    "\n",
    "        pred = model(img)\n",
    "        print(pred.shape)\n",
    "        train_loss = loss_func(pred, label)\n",
    "        train_loss = train_loss[mask]\n",
    "        train_loss = train_loss.mean()\n",
    "\n",
    "        pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "        pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "        mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "        pred_m = pred_f[mask_f, :]\n",
    "        label_m = label[mask]\n",
    "        current_train_acc = accuracy(pred_m, label_m)\n",
    "        accuracy_dict[\"train\"].append(current_train_acc)\n",
    "\n",
    "        pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "        mask_miou = (label != 0)\n",
    "        pred_labels[~mask] = 0\n",
    "        current_train_miou = miou(pred_labels, label)\n",
    "        miou_dict[\"train\"].append(current_train_miou)\n",
    "        current_train_dice = dice(pred_labels, label)\n",
    "        dice_dict[\"train\"].append(current_train_dice)\n",
    "        current_train_mcf1s = mcf1s(pred_labels, label)\n",
    "        mcf1s_dict[\"train\"].append(current_train_mcf1s)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in val_loader:\n",
    "            test_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img = test_item['frame']\n",
    "            label = test_item['label']\n",
    "            mask = test_item['mask']\n",
    "    \n",
    "            label[~mask] = 0\n",
    "    \n",
    "            pred = model(img)\n",
    "            test_loss = loss_func(pred, label)\n",
    "            test_loss = test_loss[mask]\n",
    "            test_loss = test_loss.mean()\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "            current_test_acc = accuracy(pred_m, label_m)\n",
    "            accuracy_dict[\"val\"].append(current_test_acc)\n",
    "\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "            current_test_miou = miou(pred_labels, label)\n",
    "            miou_dict[\"val\"].append(current_test_miou)\n",
    "            current_test_dice = dice(pred_labels, label)\n",
    "            dice_dict[\"val\"].append(current_test_dice)\n",
    "            current_test_mcf1s = mcf1s(pred_labels, label)\n",
    "            mcf1s_dict[\"val\"].append(current_test_mcf1s)\n",
    "        \n",
    "            total_test_loss += test_loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_test_loss = total_test_loss / test_steps\n",
    "\n",
    "    # Store loss history for graphical visualization\n",
    "    H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
    "\n",
    "    print(\"CURRENT EPOCH: {}/{}\".format(epochs + 1, n_epochs))\n",
    "    print(\"Train loss: {:.10f}, Test loss {:.4f}\".format(avg_train_loss, avg_test_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training took {:.2f}s\".format(end_time - start_time))\n",
    "print(\"Accuracy: {:.4f} on training and {:.4f} on testing\".format(current_train_acc, current_test_acc))\n",
    "print(\"Mean IOU: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"Dice: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"F1 Macro: {:.4f} on training and {:.4f} on testing\".format(current_train_mcf1s, current_test_mcf1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = \"ufgsim_transRVNet_torch.pt\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f596aa",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "train_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"train\"]]\n",
    "val_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "train_miou = [x.cpu().numpy() for x in miou_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_miou, label=\"train_miou\")\n",
    "plt.plot(val_miou, label=\"val_miou\")\n",
    "plt.title(\"Mean IOU\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"miou\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice\n",
    "train_dice = [x.cpu().numpy() for x in dice_dict[\"train\"]]\n",
    "val_dice = [x.cpu().numpy() for x in dice_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_dice, label=\"train_dice\")\n",
    "plt.plot(val_dice, label=\"val_dice\")\n",
    "plt.title(\"Dice\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"dice score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b54ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Macro\n",
    "train_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"train\"]]\n",
    "val_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_mcf1s, label=\"train_mcf1s\")\n",
    "plt.plot(val_mcf1s, label=\"val_mcf1s\")\n",
    "plt.title(\"F1 Macro\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"mcf1s score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
