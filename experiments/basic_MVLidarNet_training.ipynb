{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d91419c-4aba-4b86-9712-f1548c052ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorcloud.chen2020mvlidarnet import MVLidarNet, SemanticSegmentationTask\n",
    "from colorcloud.UFGsim2024infufg import ProjectionToTensorTransformSim, UFGSimDataset, SphericalProjection, ProjectionSimTransform\n",
    "from colorcloud.behley2019iccv import SphericalProjection, SemanticSegmentationLDM\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import lightning as L\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from datetime import datetime\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.segmentation import MeanIoU\n",
    "from torchmetrics.classification import Dice\n",
    "from torchmetrics.classification import MulticlassF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e289abb-4019-47ee-888c-eb34f7f0d97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b6579-1f18-456d-8d4a-23ce6eeaf2fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Lightning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0ce2a0-9b07-4c79-a7ce-c3dc4834bfc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../UFGSim/ufg-sim.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m SemanticSegmentationSimLDM(eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m epoch_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mtrain_dataloader())\n",
      "File \u001b[0;32m/workspace/colorcloud/colorcloud/UFGsim2024infufg.py:352\u001b[0m, in \u001b[0;36mSemanticSegmentationSimLDM.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 352\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mUFGSimDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviz_tfm\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviz_tfm \u001b[38;5;241m=\u001b[39m ProjectionSimVizTransform(ds\u001b[38;5;241m.\u001b[39mcolor_map_rgb_np, ds\u001b[38;5;241m.\u001b[39mlearning_map_inv_np)\n",
      "File \u001b[0;32m/workspace/colorcloud/colorcloud/UFGsim2024infufg.py:27\u001b[0m, in \u001b[0;36mUFGSimDataset.__init__\u001b[0;34m(self, data_path, split, transform)\u001b[0m\n\u001b[1;32m     24\u001b[0m yaml_path \u001b[38;5;241m=\u001b[39m data_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mufg-sim.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mufgsim_velodyne_path \u001b[38;5;241m=\u001b[39m data_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaser_scans\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myaml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     28\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m     30\u001b[0m lasers \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m][split]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../UFGSim/ufg-sim.yaml'"
     ]
    }
   ],
   "source": [
    "data = SemanticSegmentationLDM(eval_batch_size=4, train_batch_size=4)\n",
    "data.setup('fit')\n",
    "epoch_steps = len(data.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb12a14-47a9-4fc9-aacb-94de5eb0a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20056306-3d52-44b4-abc3-b0e8c40bd861",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MVLidarNet(in_channels=4, n_classes=13).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7742f00-8c56-49ec-b2b0-193928462d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7305321-acf2-4de3-9c8c-e71d7c2fd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "learner = SemanticSegmentationTask(\n",
    "    model,\n",
    "    CrossEntropyLoss(reduction='none'),\n",
    "    data.viz_tfm,\n",
    "    total_steps=n_epochs*epoch_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528fa78-1897-47ef-83ea-1b9f49ca4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"UFGSim-MVLidarNet\"\n",
    "timestamp = datetime.now().strftime(\"%d/%m/%Y_%H:%M:%S\")\n",
    "experiment_name = f'{model_name}_{timestamp}'\n",
    "wandb_logger = WandbLogger(project=\"colorcloud\", name=experiment_name, log_model=\"all\")\n",
    "wandb_logger.watch(learner.model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19479da-9b8f-4629-a497-f49cd4cd8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer = L.Trainer(max_epochs=n_epochs, logger=wandb_logger)\n",
    "trainer.fit(learner, data)\n",
    "trainer.save_checkpoint(\"ufgsim_mvlidarnet_1.ckpt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e6276-a0bb-4445-8816-2d9988127d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416215d4-5f16-4b53-9f3e-1d592c7ea8b7",
   "metadata": {},
   "source": [
    "# Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e1afe-418a-4dad-a2cf-2f90b83bafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = SphericalProjection(fov_up_deg=15., fov_down_deg=-15., W=440, H=16)\n",
    "tfms = v2.Compose([\n",
    "    ProjectionSimTransform(proj),\n",
    "    ProjectionToTensorTransformSim(),\n",
    "])\n",
    "\n",
    "data_path = '/workspace/data'\n",
    "train_dataset = UFGSimDataset(data_path=data_path, split='train', transform=tfms)\n",
    "val_dataset = UFGSimDataset(data_path=data_path, split='valid', transform=tfms)\n",
    "\n",
    "print(\"Size of train dataset: \", len(train_dataset))\n",
    "print(\"Size of val dataset: \", len(val_dataset))\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da64a8a-8bb7-4042-a41c-65a65ee91d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "model = MVLidarNet(in_channels=4, n_classes=13).to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "opt = AdamW(model.parameters(), lr=5e-4, eps=1e-5)\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=model.n_classes).to(device)\n",
    "accuracy_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "miou = MeanIoU(num_classes=model.n_classes).to(device)\n",
    "miou_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "dice = Dice(num_classes=model.n_classes).to(device)\n",
    "dice_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "mcf1s = MulticlassF1Score(num_classes=model.n_classes, average=\"macro\").to(device)\n",
    "mcf1s_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "train_steps = len(train_loader) // batch_size\n",
    "test_steps = len(val_loader) // batch_size\n",
    "H = {\"train_loss\": [], \"test_loss\": []} # store loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40ac37-6c88-4815-a01f-d00eb645ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epochs in tqdm(range(n_epochs)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "        img = train_item['frame']\n",
    "        label = train_item['label']\n",
    "        mask = train_item['mask']\n",
    "\n",
    "        label[~mask] = 0\n",
    "\n",
    "        pred = model(img)\n",
    "        train_loss = loss_func(pred, label)\n",
    "        train_loss = train_loss[mask]\n",
    "        train_loss = train_loss.mean()\n",
    "\n",
    "        pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "        pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "        mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "        pred_m = pred_f[mask_f, :]\n",
    "        label_m = label[mask]\n",
    "        current_train_acc = accuracy(pred_m, label_m)\n",
    "        accuracy_dict[\"train\"].append(current_train_acc)\n",
    "\n",
    "        pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "        mask_miou = (label != 0)\n",
    "        pred_labels[~mask] = 0\n",
    "        current_train_miou = miou(pred_labels, label)\n",
    "        miou_dict[\"train\"].append(current_train_miou)\n",
    "        current_train_dice = dice(pred_labels, label)\n",
    "        dice_dict[\"train\"].append(current_train_dice)\n",
    "        current_train_mcf1s = mcf1s(pred_labels, label)\n",
    "        mcf1s_dict[\"train\"].append(current_train_mcf1s)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in val_loader:\n",
    "            test_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img = test_item['frame']\n",
    "            label = test_item['label']\n",
    "            mask = test_item['mask']\n",
    "    \n",
    "            label[~mask] = 0\n",
    "    \n",
    "            pred = model(img)\n",
    "            test_loss = loss_func(pred, label)\n",
    "            test_loss = test_loss[mask]\n",
    "            test_loss = test_loss.mean()\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "            current_test_acc = accuracy(pred_m, label_m)\n",
    "            accuracy_dict[\"val\"].append(current_test_acc)\n",
    "\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "            current_test_miou = miou(pred_labels, label)\n",
    "            miou_dict[\"val\"].append(current_test_miou)\n",
    "            current_test_dice = dice(pred_labels, label)\n",
    "            dice_dict[\"val\"].append(current_test_dice)\n",
    "            current_test_mcf1s = mcf1s(pred_labels, label)\n",
    "            mcf1s_dict[\"val\"].append(current_test_mcf1s)\n",
    "        \n",
    "            total_test_loss += test_loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_test_loss = total_test_loss / test_steps\n",
    "\n",
    "    # Store loss history for graphical visualization\n",
    "    H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
    "\n",
    "    print(\"CURRENT EPOCH: {}/{}\".format(epochs + 1, n_epochs))\n",
    "    print(\"Train loss: {:.10f}, Test loss {:.4f}\".format(avg_train_loss, avg_test_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training took {:.2f}s\".format(end_time - start_time))\n",
    "print(\"Accuracy: {:.4f} on training and {:.4f} on testing\".format(current_train_acc, current_test_acc))\n",
    "print(\"Mean IOU: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"Dice: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))\n",
    "print(\"F1 Macro: {:.4f} on training and {:.4f} on testing\".format(current_train_mcf1s, current_test_mcf1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1837824-4f4b-480d-be8a-5b3dd7a3a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = \"ufgsim_mvlidar_torch.pt\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da7af9-624e-4bd9-9c7b-b1d307b34dbd",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43edc0-7fef-4fd0-aced-f984ae3119e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbb31a-d876-42a3-9598-81f3625ad1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "train_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"train\"]]\n",
    "val_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db337cf-f4d8-403d-869f-40a1d3766cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "train_miou = [x.cpu().numpy() for x in miou_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_miou, label=\"train_miou\")\n",
    "plt.plot(val_miou, label=\"val_miou\")\n",
    "plt.title(\"Mean IOU\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"miou\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3479547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice\n",
    "train_dice = [x.cpu().numpy() for x in dice_dict[\"train\"]]\n",
    "val_dice = [x.cpu().numpy() for x in dice_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_dice, label=\"train_dice\")\n",
    "plt.plot(val_dice, label=\"val_dice\")\n",
    "plt.title(\"Dice\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"dice score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05620d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Macro\n",
    "train_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"train\"]]\n",
    "val_mcf1s = [x.cpu().numpy() for x in mcf1s_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_mcf1s, label=\"train_mcf1s\")\n",
    "plt.plot(val_mcf1s, label=\"val_mcf1s\")\n",
    "plt.title(\"F1 Macro\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"mcf1s score\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
