{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d91419c-4aba-4b86-9712-f1548c052ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorcloud.chen2020mvlidarnet import MVLidarNet, SemanticSegmentationTask\n",
    "from colorcloud.UFGsim2024infufg import SemanticSegmentationSimLDM, ProjectionSimVizTransform, UFGSimDataset\n",
    "from colorcloud.UFGsim2024infufg import ProjectionToTensorTransformSim, UFGSimDataset, SphericalProjection, ProjectionSimTransform\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import lightning as L\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from datetime import datetime\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.segmentation import MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e289abb-4019-47ee-888c-eb34f7f0d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b6579-1f18-456d-8d4a-23ce6eeaf2fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Lightning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df0ce2a0-9b07-4c79-a7ce-c3dc4834bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SemanticSegmentationSimLDM(eval_batch_size=4, train_batch_size=4)\n",
    "data.setup('fit')\n",
    "epoch_steps = len(data.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb12a14-47a9-4fc9-aacb-94de5eb0a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20056306-3d52-44b4-abc3-b0e8c40bd861",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MVLidarNet(in_channels=4, n_classes=13).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7742f00-8c56-49ec-b2b0-193928462d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7305321-acf2-4de3-9c8c-e71d7c2fd4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "learner = SemanticSegmentationTask(\n",
    "    model,\n",
    "    CrossEntropyLoss(reduction='none'),\n",
    "    data.viz_tfm,\n",
    "    total_steps=n_epochs*epoch_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528fa78-1897-47ef-83ea-1b9f49ca4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"UFGSim-MVLidarNet\"\n",
    "timestamp = datetime.now().strftime(\"%d/%m/%Y_%H:%M:%S\")\n",
    "experiment_name = f'{model_name}_{timestamp}'\n",
    "wandb_logger = WandbLogger(project=\"colorcloud\", name=experiment_name, log_model=\"all\")\n",
    "wandb_logger.watch(learner.model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19479da-9b8f-4629-a497-f49cd4cd8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "trainer = L.Trainer(max_epochs=n_epochs, logger=wandb_logger)\n",
    "trainer.fit(learner, data)\n",
    "trainer.save_checkpoint(\"ufgsim_mvlidarnet_1.ckpt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e6276-a0bb-4445-8816-2d9988127d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416215d4-5f16-4b53-9f3e-1d592c7ea8b7",
   "metadata": {},
   "source": [
    "# Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "767e1afe-418a-4dad-a2cf-2f90b83bafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = SphericalProjection(fov_up_deg=15., fov_down_deg=-15., W=440, H=16)\n",
    "tfms = v2.Compose([\n",
    "    ProjectionSimTransform(proj),\n",
    "    ProjectionToTensorTransformSim(),\n",
    "])\n",
    "\n",
    "data_path = '/workspace/data'\n",
    "train_dataset = UFGSimDataset(data_path=data_path, split='train', transform=tfms)\n",
    "val_dataset = UFGSimDataset(data_path=data_path, split='valid', transform=tfms)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3da64a8a-8bb7-4042-a41c-65a65ee91d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "model = MVLidarNet(in_channels=4, n_classes=13).to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "opt = AdamW(model.parameters(), lr=5e-4, eps=1e-5)\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=model.n_classes).to(device)\n",
    "accuracy_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "miou = MeanIoU(num_classes=model.n_classes).to(device)\n",
    "miou_dict = {\"train\": [], \"val\": []}\n",
    "\n",
    "train_steps = len(train_loader) // batch_size\n",
    "test_steps = len(val_loader) // batch_size\n",
    "H = {\"train_loss\": [], \"test_loss\": []} # store loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40ac37-6c88-4815-a01f-d00eb645ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epochs in tqdm(range(n_epochs)):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        train_item = {key: value.to(device) for key, value in batch.items()}\n",
    "        img = train_item['frame']\n",
    "        label = train_item['label']\n",
    "        mask = train_item['mask']\n",
    "\n",
    "        label[~mask] = 0\n",
    "\n",
    "        pred = model(img)\n",
    "        train_loss = loss_func(pred, label)\n",
    "        train_loss = train_loss[mask]\n",
    "        train_loss = train_loss.mean()\n",
    "\n",
    "        pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "        pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "        mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "        pred_m = pred_f[mask_f, :]\n",
    "        label_m = label[mask]\n",
    "        current_train_acc = accuracy(pred_m, label_m)\n",
    "        accuracy_dict[\"train\"].append(current_train_acc)\n",
    "\n",
    "        pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "        mask_miou = (label != 0)\n",
    "        pred_labels[~mask] = 0\n",
    "        current_train_miou = miou(pred_labels, label)\n",
    "        miou_dict[\"train\"].append(current_train_miou)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        train_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_train_loss += train_loss\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for batch in val_loader:\n",
    "            test_item = {key: value.to(device) for key, value in batch.items()}\n",
    "            img = test_item['frame']\n",
    "            label = test_item['label']\n",
    "            mask = test_item['mask']\n",
    "    \n",
    "            label[~mask] = 0\n",
    "    \n",
    "            pred = model(img)\n",
    "            test_loss = loss_func(pred, label)\n",
    "            test_loss = test_loss[mask]\n",
    "            test_loss = test_loss.mean()\n",
    "\n",
    "            pred_f = torch.permute(pred, (0, 2, 3, 1)) # N,C,H,W -> N,H,W,C\n",
    "            pred_f = torch.flatten(pred_f, 0, -2)      # N,H,W,C -> N*H*W,C\n",
    "            mask_f = torch.flatten(mask)               # N,H,W   -> N*H*W\n",
    "            pred_m = pred_f[mask_f, :]\n",
    "            label_m = label[mask]\n",
    "            current_test_acc = accuracy(pred_m, label_m)\n",
    "            accuracy_dict[\"val\"].append(current_test_acc)\n",
    "\n",
    "            pred_labels = torch.argmax(pred, dim=1).to(device)\n",
    "            mask_miou = (label != 0)\n",
    "            pred_labels[~mask] = 0\n",
    "            current_test_miou = miou(pred_labels, label)\n",
    "            miou_dict[\"val\"].append(current_test_miou)\n",
    "        \n",
    "            total_test_loss += test_loss\n",
    "\n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    avg_test_loss = total_test_loss / test_steps\n",
    "\n",
    "    # Store loss history for graphical visualization\n",
    "    H[\"train_loss\"].append(avg_train_loss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avg_test_loss.cpu().detach().numpy())\n",
    "\n",
    "    print(\"CURRENT EPOCH: {}/{}\".format(epochs + 1, n_epochs))\n",
    "    print(\"Train loss: {:.10f}, Test loss {:.4f}\".format(avg_train_loss, avg_test_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training took {:.2f}s\".format(end_time - start_time))\n",
    "print(\"Accuracy: {:.4f} on training and {:.4f} on testing\".format(current_train_acc, current_test_acc))\n",
    "print(\"Mean IOU: {:.4f} on training and {:.4f} on testing\".format(current_train_miou, current_test_miou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1837824-4f4b-480d-be8a-5b3dd7a3a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_name = \"ufgsim_mvlidar_torch.pt\"\n",
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da7af9-624e-4bd9-9c7b-b1d307b34dbd",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43edc0-7fef-4fd0-aced-f984ae3119e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbb31a-d876-42a3-9598-81f3625ad1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\n",
    "train_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"train\"]]\n",
    "val_accuracy = [x.cpu().numpy() for x in accuracy_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db337cf-f4d8-403d-869f-40a1d3766cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "train_miou = [x.cpu().numpy() for x in miou_dict[\"train\"]]\n",
    "val_miou = [x.cpu().numpy() for x in miou_dict[\"val\"]]\n",
    "\n",
    "plt.plot(train_miou, label=\"train_miou\")\n",
    "plt.plot(val_miou, label=\"val_miou\")\n",
    "plt.title(\"Mean IOU\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"miou\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
