{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44def1-f8b8-41a7-b859-f798f6a8ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b286f2c-33a7-4cf0-873f-5cf2013ec0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorcloud.datatools import SemanticKITTIDataset, SphericalProjectionTransform, ProjectionToTensorTransform\n",
    "from colorcloud.models import RIUNet\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022643a5-7b90-479c-b3e7-f1b588310046",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = RIUNet()\n",
    "        self.loss_fn = CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        img, label, mask = batch\n",
    "        label[~mask] = 0\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = self.net(img)\n",
    "        loss = self.loss_fn(pred, label)\n",
    "        loss = loss[mask].mean()\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ab7dd-5d2d-46ba-88f9-8a07691f8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../Cloud2DImageConverter/point_clouds/semantic_kitti/'\n",
    "ds = SemanticKITTIDataset(data_path)\n",
    "\n",
    "tfms = v2.Compose([\n",
    "    SphericalProjectionTransform(fov_up_deg=4., fov_down_deg=-26., W=1024, H=64),\n",
    "    ProjectionToTensorTransform(),\n",
    "])\n",
    "ds.set_transform(tfms)\n",
    "\n",
    "bs = 3\n",
    "dl = DataLoader(ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc3a2a-573e-424c-8ddf-0e2beb232adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | net     | RIUNet           | 31.0 M\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "31.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 M    Total params\n",
      "124.160   Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a1e9d7c4cf47cdb20a48a12e903f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "trainer.fit(model=LitModel(), train_dataloaders=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50242a5e-a1df-468e-87dd-1f14d154cec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
