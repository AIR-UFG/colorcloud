{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c69cc-d200-4710-addf-8062129cfe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6d3ae-45a2-486d-9fab-a7b1b854babc",
   "metadata": {},
   "source": [
    "# biasutti2019riu\n",
    "\n",
    "> Module that implements the model from [RIU-Net: Embarrassingly simple semantic segmentation of 3D LiDAR point cloud](https://arxiv.org/abs/1905.08748)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0028db0e-08f5-4c13-a6fc-d50701159819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp biasutti2019riu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407d042-2215-4712-9e2c-d951a8cf0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d, ReLU, ModuleList, MaxPool2d, ConvTranspose2d, CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from lightning import LightningDataModule, LightningModule\n",
    "from colorcloud.behley2019iccv import SemanticKITTIDataset, UnfoldingProjection, ProjectionTransform, ProjectionToTensorTransform\n",
    "from torchvision.transforms import v2\n",
    "from torchmetrics.classification import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818cc4f-4ebb-454d-9ab1-edeb6f5b22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Block(Module):\n",
    "    \"Convolutional block repeatedly used in the RIU-Net encoder and decoder.\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.net = Sequential(\n",
    "            Conv2d(in_channels, out_channels, 3, 1, 1, bias=False, padding_mode='circular'), \n",
    "            BatchNorm2d(out_channels, momentum=0.01), \n",
    "            ReLU(),\n",
    "            Conv2d(out_channels, out_channels, 3, 1, 1, bias=False, padding_mode='circular'), \n",
    "            BatchNorm2d(out_channels, momentum=0.01), \n",
    "            ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893cb46-6646-4581-8683-5ffaa8425c1b",
   "metadata": {},
   "source": [
    "It implements the following architecture:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A((\"\n",
    "  Input\n",
    "  (bs, in_c, h, w)\")) --> B[\"\n",
    "  Conv(3x3)\n",
    "  in_c -> out_c\"]\n",
    "  B --> C[\"BatchNorm2d\"]\n",
    "  C --> D[\"ReLU\"]\n",
    "  D --> E[\"\n",
    "  Conv(3x3)\n",
    "  out_c -> out_c\"]\n",
    "  E --> F[\"BatchNorm2d\"]\n",
    "  F --> G[\"ReLU\"]\n",
    "  G --> H((\"\n",
    "  Output\n",
    "  (bs, out_c, h, w)\"))\n",
    "```\n",
    "\n",
    "Here is an example on how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46d424-aa62-4686-b746-b5f144063376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 512]) == (1, 64, 64, 512)\n"
     ]
    }
   ],
   "source": [
    "bs, in_c, out_c, h, w = 1, 5, 64, 64, 512\n",
    "inp = torch.randn(bs, in_c, h, w)\n",
    "\n",
    "b = Block(in_c, out_c)\n",
    "outp = b(inp)\n",
    "assert outp.shape == (bs, out_c, h, w)\n",
    "print(outp.shape, f'== ({bs}, {out_c}, {h}, {w})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e51fb-d9ee-48f3-a4c9-b6a26e8788a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(Module):\n",
    "    \"RIU-Net encoder architecture.\"\n",
    "    def __init__(self, channels=(5, 64, 128, 256, 512, 1024)):\n",
    "        super().__init__()\n",
    "        self.blocks = ModuleList(\n",
    "            [Block(channels[i], channels[i+1]) for i in range(len(channels)-1)]\n",
    "        )\n",
    "        self.pool = MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc_features = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            enc_features.append(x)\n",
    "            x = self.pool(x)\n",
    "        return enc_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf6a19-277f-43a2-ad10-efb3a96164fb",
   "metadata": {},
   "source": [
    "It implements the following architecture:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A((\"\n",
    "  Input\n",
    "  (bs, 5, h, w)\")) --> B[\"\n",
    "  Block\n",
    "  5 -> 64\"]\n",
    "  B --> C[\"MaxPool(2x2)\"]\n",
    "  C --> D[\"\n",
    "  Block\n",
    "  64 -> 128\"]\n",
    "  D --> E[\"MaxPool(2x2)\"]\n",
    "  E --> F[\"\n",
    "  Block\n",
    "  128 -> 256\"]\n",
    "  F --> G[\"MaxPool(2x2)\"]\n",
    "  G --> H[\"\n",
    "  Block\n",
    "  256 -> 512\"]\n",
    "  H --> I[\"MaxPool(2x2)\"]\n",
    "  I --> J[\"\n",
    "  Block\n",
    "  512 -> 1024\"]\n",
    "  B --> L((\"\n",
    "  Output\n",
    "  [(bs, 64, h, w),\n",
    "  (bs, 128, h/2, w/2),\n",
    "  (bs, 256, h/4, w/4),\n",
    "  (bs, 512, h/8, w/8),\n",
    "  (bs, 1024, h/16, w/16)]\"))\n",
    "  D --> L\n",
    "  F --> L\n",
    "  H --> L\n",
    "  J --> L\n",
    "```\n",
    "\n",
    "Here is an example on how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0961c1d1-19f7-402e-bdb5-e1b12dcff13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 64, 64, 512]),\n",
       " torch.Size([1, 128, 32, 256]),\n",
       " torch.Size([1, 256, 16, 128]),\n",
       " torch.Size([1, 512, 8, 64]),\n",
       " torch.Size([1, 1024, 4, 32])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder()\n",
    "outp = enc(inp)\n",
    "[o.shape for o in outp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e039c48-213f-4411-8d6d-884ecb8f7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Decoder(Module):\n",
    "    \"RIU-Net decoder architecture.\"\n",
    "    def __init__(self, channels=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.upconvs = ModuleList(\n",
    "            [ConvTranspose2d(channels[i], channels[i+1], 6, 2, 2) for i in range(len(channels)-1)]\n",
    "        )\n",
    "        self.blocks = ModuleList(\n",
    "            [Block(channels[i], channels[i+1]) for i in range(len(channels)-1)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, enc_features):\n",
    "        x = enc_features[-1]\n",
    "        for i, (upconv, block) in enumerate(zip(self.upconvs, self.blocks)):\n",
    "            x = upconv(x)\n",
    "            x = torch.cat([x, enc_features[-(i+2)]], dim=1)\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30318b56-525f-4c6d-8368-9ea7ce3fef25",
   "metadata": {},
   "source": [
    "It implements the following architecture:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A((\"\n",
    "  Input\n",
    "  [(bs, 1024, h/16, w/16),\n",
    "  (bs, 512, h/8, w/8),\n",
    "  (bs, 256, h/4, w/4),\n",
    "  (bs, 128, h/2, w/2),\n",
    "  (bs, 64, h, w)]\")) --> B[\"\n",
    "  ConvTranspose(2x2)\n",
    "  1024 -> 512\"]\n",
    "  B --> C[\"\n",
    "  Block\n",
    "  concat(512,512) -> 512\"]\n",
    "  A --> C\n",
    "  C --> D[\"\n",
    "  ConvTranspose(2x2)\n",
    "  512 -> 256\"]\n",
    "  D --> E[\"\n",
    "  Block\n",
    "  concat(256,256) -> 256\"]\n",
    "  A --> E\n",
    "  E --> F[\"\n",
    "  ConvTranspose(2x2)\n",
    "  256 -> 128\"]\n",
    "  F --> G[\"\n",
    "  Block\n",
    "  concat(128,128) -> 128\"]\n",
    "  A --> G\n",
    "  G --> H[\"\n",
    "  ConvTranspose(2x2)\n",
    "  128 -> 64\"]\n",
    "  H --> I[\"\n",
    "  Block\n",
    "  concat(64,64) -> 64\"]\n",
    "  A --> I\n",
    "  I --> J((\"\n",
    "  Output\n",
    "  (bs, 64, h, w)\"))\n",
    "```\n",
    "\n",
    "Here is an example on how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b30e7-5000-462b-8a1e-c46c9ad5f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 512]) == (1, 64, 64, 512)\n"
     ]
    }
   ],
   "source": [
    "dec = Decoder()\n",
    "fts = dec(outp)\n",
    "assert fts.shape == (bs, out_c, h, w)\n",
    "print(fts.shape, f'== ({bs}, {out_c}, {h}, {w})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b5b8a-c437-4e65-8027-182568366723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RIUNet(Module):\n",
    "    \"RIU-Net complete architecture.\"\n",
    "    def __init__(self, in_channels=5, hidden_channels=(64, 128, 256, 512, 1024), n_classes=20):\n",
    "        super().__init__()\n",
    "        self.backbone = Sequential(\n",
    "            Encoder((in_channels, *hidden_channels)),\n",
    "            Decoder(hidden_channels[::-1])\n",
    "        )\n",
    "        self.head = Conv2d(hidden_channels[0], n_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        prediction = self.head(features)\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f598dd-e2ca-4b49-90b9-8641cd2e9f99",
   "metadata": {},
   "source": [
    "It implements the following architecture:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A((\"\n",
    "  Input\n",
    "  (bs, 5, h, w)\")) --> B[\"Encoder\"]\n",
    "  B --> C[\"Decoder\"]\n",
    "  C --> D[\"\n",
    "  Conv(1x1)\n",
    "  64 -> 20\"]\n",
    "  D --> E((\"\n",
    "  Output\n",
    "  (bs, 20, h, w)\"))\n",
    "```\n",
    "\n",
    "Here is an example on how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcce5f-3640-4f92-9f8d-f2e47389dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 64, 512]) == (1, 20, 64, 512)\n"
     ]
    }
   ],
   "source": [
    "n_classes=20\n",
    "model = RIUNet()\n",
    "logits = model(inp)\n",
    "assert logits.shape == (bs, n_classes, h, w)\n",
    "print(logits.shape, f'== ({bs}, {n_classes}, {h}, {w})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad2781-7937-4383-82b3-a34e0fd18a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LitDataModule(LightningDataModule):\n",
    "    \"Lightning DataModule to facilitate reproducibility of experiments in the original paper.\"\n",
    "    def __init__(self, train_batch_size=8, eval_batch_size=16, num_workers=8):\n",
    "        super().__init__()\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def setup(self, stage: str):\n",
    "        data_path = '/workspace/data'\n",
    "        proj = UnfoldingProjection(W=512, H=64)\n",
    "        tfms = v2.Compose([\n",
    "            ProjectionTransform(proj),\n",
    "            ProjectionToTensorTransform(),\n",
    "        ])\n",
    "        if stage == \"fit\":\n",
    "            ds = SemanticKITTIDataset(data_path, transform=tfms)\n",
    "            self.ds_train, self.ds_val = random_split(\n",
    "                ds, [0.7, 0.3], generator=torch.Generator().manual_seed(42)\n",
    "            )\n",
    "        if stage == \"test\":\n",
    "            self.ds_test = SemanticKITTIDataset(data_path, is_train=False, transform=tfms)\n",
    "        if stage == \"predict\":\n",
    "            self.ds_predict = SemanticKITTIDataset(data_path, is_train=False, transform=tfms)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, batch_size=self.train_batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=self.eval_batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, batch_size=2*self.eval_batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.ds_predict, batch_size=self.eval_batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc6c14-ddd4-4381-8820-3f9c16d19465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LitModel(LightningModule):\n",
    "    \"Lightning Module to facilitate reproducibility of experiments in the original paper.\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn = BatchNorm2d(5, affine=False, momentum=None)\n",
    "        self.net = RIUNet()\n",
    "        self.loss_fn = CrossEntropyLoss(reduction='none')\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=20)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=20)\n",
    "\n",
    "    def repetitive_step_routine(self, batch, batch_idx, stage, metric):\n",
    "        img, label, mask = batch\n",
    "        label[~mask] = 0\n",
    "\n",
    "        bn_img = self.bn(img)\n",
    "        pred = self.net(bn_img)\n",
    "        \n",
    "        loss = self.loss_fn(pred, label)\n",
    "        std = loss[mask].std()\n",
    "        loss = loss[mask].mean()\n",
    "\n",
    "        pred_f = torch.permute(pred, (1, 0, 2, 3))\n",
    "        pred_f = torch.flatten(pred_f, 1)\n",
    "        mask_f = torch.flatten(mask)\n",
    "        pred_m = pred_f[:, mask_f]\n",
    "        pred_m = torch.permute(pred_m, (1, 0))\n",
    "        label_m = label[mask]\n",
    "        metric(pred_m, label_m)\n",
    "\n",
    "        self.log(f\"{stage}_loss_std\", std)\n",
    "        self.log(f\"{stage}_acc_step\", metric)\n",
    "        self.log(f\"{stage}_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.repetitive_step_routine(batch, batch_idx, \"train\", self.train_accuracy)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log('train_acc_epoch', self.train_accuracy)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.repetitive_step_routine(batch, batch_idx, \"val\", self.val_accuracy)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # log epoch metric\n",
    "        self.log('val_acc_epoch', self.val_accuracy)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ecf63-72c5-4532-8198-f32aea044af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
